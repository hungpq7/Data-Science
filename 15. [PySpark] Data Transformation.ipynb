{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Miscellaneous techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Mapping\n",
    "Mapping in PySpark requires using the `udf()` function, which allows a Python function to work on PySpark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>manufacturer</th><th>model</th><th>type</th><th>min_price</th><th>price</th><th>max_price</th><th>mpg_city</th><th>mpg_highway</th><th>airbags</th><th>drive_train</th><th>cylinders</th><th>engine_size</th><th>horsepower</th><th>rpm</th><th>rev_per_mile</th><th>man_trans_avail</th><th>fuel_tank_capacity</th><th>passengers</th><th>length</th><th>wheelbase</th><th>width</th><th>turn_circle</th><th>rear_seat_room</th><th>luggage_room</th><th>weight</th><th>origin</th><th>make</th></tr>\n",
       "<tr><td>Chevrolet</td><td>Cavalier</td><td>Compact</td><td>8.5</td><td>13.4</td><td>18.3</td><td>25</td><td>36</td><td>None</td><td>Front</td><td>4.0</td><td>2.2</td><td>110</td><td>5200</td><td>2380</td><td>Yes</td><td>15.2</td><td>5</td><td>182</td><td>101</td><td>66</td><td>38</td><td>25.0</td><td>13.0</td><td>2490</td><td>USA</td><td>Chevrolet Cavalier</td></tr>\n",
       "<tr><td>Chevrolet</td><td>Corsica</td><td>Compact</td><td>11.4</td><td>11.4</td><td>11.4</td><td>25</td><td>34</td><td>Driver only</td><td>Front</td><td>4.0</td><td>2.2</td><td>110</td><td>5200</td><td>2665</td><td>Yes</td><td>15.6</td><td>5</td><td>184</td><td>103</td><td>68</td><td>39</td><td>26.0</td><td>14.0</td><td>2785</td><td>USA</td><td>Chevrolet Corsica</td></tr>\n",
       "<tr><td>Chevrolet</td><td>Camaro</td><td>Sporty</td><td>13.4</td><td>15.1</td><td>16.8</td><td>19</td><td>28</td><td>Driver &amp; Passenger</td><td>Rear</td><td>6.0</td><td>3.4</td><td>160</td><td>4600</td><td>1805</td><td>Yes</td><td>15.5</td><td>4</td><td>193</td><td>101</td><td>74</td><td>43</td><td>25.0</td><td>13.0</td><td>3240</td><td>USA</td><td>Chevrolet Camaro</td></tr>\n",
       "<tr><td>Chevrolet</td><td>Lumina</td><td>Midsize</td><td>13.4</td><td>15.9</td><td>18.4</td><td>21</td><td>29</td><td>None</td><td>Front</td><td>4.0</td><td>2.2</td><td>110</td><td>5200</td><td>2595</td><td>No</td><td>16.5</td><td>6</td><td>198</td><td>108</td><td>71</td><td>40</td><td>28.5</td><td>16.0</td><td>3195</td><td>USA</td><td>Chevrolet Lumina</td></tr>\n",
       "<tr><td>Chevrolet</td><td>Lumina_APV</td><td>Van</td><td>14.7</td><td>16.3</td><td>18.0</td><td>18</td><td>23</td><td>None</td><td>Front</td><td>6.0</td><td>3.8</td><td>170</td><td>4800</td><td>1690</td><td>No</td><td>20.0</td><td>7</td><td>178</td><td>110</td><td>74</td><td>44</td><td>30.5</td><td>null</td><td>3715</td><td>USA</td><td>Chevrolet Lumina_APV</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+----------+-------+---------+-----+---------+--------+-----------+------------------+-----------+---------+-----------+----------+----+------------+---------------+------------------+----------+------+---------+-----+-----------+--------------+------------+------+------+--------------------+\n",
       "|manufacturer|     model|   type|min_price|price|max_price|mpg_city|mpg_highway|           airbags|drive_train|cylinders|engine_size|horsepower| rpm|rev_per_mile|man_trans_avail|fuel_tank_capacity|passengers|length|wheelbase|width|turn_circle|rear_seat_room|luggage_room|weight|origin|                make|\n",
       "+------------+----------+-------+---------+-----+---------+--------+-----------+------------------+-----------+---------+-----------+----------+----+------------+---------------+------------------+----------+------+---------+-----+-----------+--------------+------------+------+------+--------------------+\n",
       "|   Chevrolet|  Cavalier|Compact|      8.5| 13.4|     18.3|      25|         36|              None|      Front|      4.0|        2.2|       110|5200|        2380|            Yes|              15.2|         5|   182|      101|   66|         38|          25.0|        13.0|  2490|   USA|  Chevrolet Cavalier|\n",
       "|   Chevrolet|   Corsica|Compact|     11.4| 11.4|     11.4|      25|         34|       Driver only|      Front|      4.0|        2.2|       110|5200|        2665|            Yes|              15.6|         5|   184|      103|   68|         39|          26.0|        14.0|  2785|   USA|   Chevrolet Corsica|\n",
       "|   Chevrolet|    Camaro| Sporty|     13.4| 15.1|     16.8|      19|         28|Driver & Passenger|       Rear|      6.0|        3.4|       160|4600|        1805|            Yes|              15.5|         4|   193|      101|   74|         43|          25.0|        13.0|  3240|   USA|    Chevrolet Camaro|\n",
       "|   Chevrolet|    Lumina|Midsize|     13.4| 15.9|     18.4|      21|         29|              None|      Front|      4.0|        2.2|       110|5200|        2595|             No|              16.5|         6|   198|      108|   71|         40|          28.5|        16.0|  3195|   USA|    Chevrolet Lumina|\n",
       "|   Chevrolet|Lumina_APV|    Van|     14.7| 16.3|     18.0|      18|         23|              None|      Front|      6.0|        3.8|       170|4800|        1690|             No|              20.0|         7|   178|      110|   74|         44|          30.5|        null|  3715|   USA|Chevrolet Lumina_APV|\n",
       "+------------+----------+-------+---------+-----+---------+--------+-----------+------------------+-----------+---------+-----------+----------+----+------------+---------------+------------------+----------+------+---------+-----+-----------+--------------+------------+------+------+--------------------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = pd.read_excel(r'data\\cars.xlsx')\n",
    "cars = spark.createDataFrame(cars.astype(str)).replace('nan', None)\n",
    "cars = cars.withColumn('price', F.col('price').cast('float'))\n",
    "cars.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.600000381469727, 15.899999618530273, 18.799999237060547]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.approxQuantile('price', [0.25, 0.5, 0.75], relativeError=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp_getPriceLevel(price):\n",
    "    if price < 11.6:\n",
    "        return 'very low'\n",
    "    elif price < 15.9:\n",
    "        return 'low'\n",
    "    elif price < 18.8:\n",
    "        return 'high'\n",
    "    else:\n",
    "        return 'very high'\n",
    "\n",
    "getPriceLevel = F.udf(lambda price: tmp_getPriceLevel(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>price</th><th>price_level</th></tr>\n",
       "<tr><td>13.4</td><td>low</td></tr>\n",
       "<tr><td>11.4</td><td>very low</td></tr>\n",
       "<tr><td>15.1</td><td>low</td></tr>\n",
       "<tr><td>15.9</td><td>low</td></tr>\n",
       "<tr><td>16.3</td><td>high</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+-----------+\n",
       "|price|price_level|\n",
       "+-----+-----------+\n",
       "| 13.4|        low|\n",
       "| 11.4|   very low|\n",
       "| 15.1|        low|\n",
       "| 15.9|        low|\n",
       "| 16.3|       high|\n",
       "+-----+-----------+"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.select('price', getPriceLevel('price').alias('price_level')).limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Window functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>employee</th><th>department</th><th>salary</th></tr>\n",
       "<tr><td>James</td><td>Sales</td><td>3000</td></tr>\n",
       "<tr><td>Harry</td><td>Sales</td><td>3500</td></tr>\n",
       "<tr><td>Ash</td><td>Sales</td><td>3000</td></tr>\n",
       "<tr><td>Michael</td><td>Sales</td><td>4600</td></tr>\n",
       "<tr><td>Robert</td><td>Sales</td><td>4100</td></tr>\n",
       "<tr><td>Maria</td><td>Finance</td><td>3000</td></tr>\n",
       "<tr><td>Wayne</td><td>Sales</td><td>3000</td></tr>\n",
       "<tr><td>Scott</td><td>Finance</td><td>3300</td></tr>\n",
       "<tr><td>Jen</td><td>Finance</td><td>3900</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>3000</td></tr>\n",
       "<tr><td>Kumar</td><td>Marketing</td><td>2000</td></tr>\n",
       "<tr><td>Saif</td><td>Sales</td><td>4100</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+----------+------+\n",
       "|employee|department|salary|\n",
       "+--------+----------+------+\n",
       "|   James|     Sales|  3000|\n",
       "|   Harry|     Sales|  3500|\n",
       "|     Ash|     Sales|  3000|\n",
       "| Michael|     Sales|  4600|\n",
       "|  Robert|     Sales|  4100|\n",
       "|   Maria|   Finance|  3000|\n",
       "|   Wayne|     Sales|  3000|\n",
       "|   Scott|   Finance|  3300|\n",
       "|     Jen|   Finance|  3900|\n",
       "|    Jeff| Marketing|  3000|\n",
       "|   Kumar| Marketing|  2000|\n",
       "|    Saif|     Sales|  4100|\n",
       "+--------+----------+------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    ('James', 'Sales', 3000),\n",
    "    ('Harry', 'Sales', 3500),\n",
    "    ('Ash', 'Sales', 3000),\n",
    "    ('Michael', 'Sales', 4600),\n",
    "    ('Robert', 'Sales', 4100),\n",
    "    ('Maria', 'Finance', 3000),\n",
    "    ('Wayne', 'Sales', 3000),\n",
    "    ('Scott', 'Finance', 3300),\n",
    "    ('Jen', 'Finance', 3900),\n",
    "    ('Jeff', 'Marketing', 3000),\n",
    "    ('Kumar', 'Marketing', 2000),\n",
    "    ('Saif', 'Sales', 4100))\n",
    " \n",
    "columns= ['employee', 'department', 'salary']\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to activate window functions, we firstly initialize the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "window = Window.partitionBy('department').orderBy('salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>employee</th><th>department</th><th>salary</th><th>row_number</th><th>rank</th><th>dense_rank</th><th>percent_rank</th><th>cume_dist</th></tr>\n",
       "<tr><td>James</td><td>Sales</td><td>3000</td><td>1</td><td>1</td><td>1</td><td>0.0</td><td>0.43</td></tr>\n",
       "<tr><td>Ash</td><td>Sales</td><td>3000</td><td>2</td><td>1</td><td>1</td><td>0.0</td><td>0.43</td></tr>\n",
       "<tr><td>Wayne</td><td>Sales</td><td>3000</td><td>3</td><td>1</td><td>1</td><td>0.0</td><td>0.43</td></tr>\n",
       "<tr><td>Harry</td><td>Sales</td><td>3500</td><td>4</td><td>4</td><td>2</td><td>0.5</td><td>0.57</td></tr>\n",
       "<tr><td>Robert</td><td>Sales</td><td>4100</td><td>5</td><td>5</td><td>3</td><td>0.67</td><td>0.86</td></tr>\n",
       "<tr><td>Saif</td><td>Sales</td><td>4100</td><td>6</td><td>5</td><td>3</td><td>0.67</td><td>0.86</td></tr>\n",
       "<tr><td>Michael</td><td>Sales</td><td>4600</td><td>7</td><td>7</td><td>4</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>Maria</td><td>Finance</td><td>3000</td><td>1</td><td>1</td><td>1</td><td>0.0</td><td>0.33</td></tr>\n",
       "<tr><td>Scott</td><td>Finance</td><td>3300</td><td>2</td><td>2</td><td>2</td><td>0.5</td><td>0.67</td></tr>\n",
       "<tr><td>Jen</td><td>Finance</td><td>3900</td><td>3</td><td>3</td><td>3</td><td>1.0</td><td>1.0</td></tr>\n",
       "<tr><td>Kumar</td><td>Marketing</td><td>2000</td><td>1</td><td>1</td><td>1</td><td>0.0</td><td>0.5</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>3000</td><td>2</td><td>2</td><td>2</td><td>1.0</td><td>1.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+----------+------+----------+----+----------+------------+---------+\n",
       "|employee|department|salary|row_number|rank|dense_rank|percent_rank|cume_dist|\n",
       "+--------+----------+------+----------+----+----------+------------+---------+\n",
       "|   James|     Sales|  3000|         1|   1|         1|         0.0|     0.43|\n",
       "|     Ash|     Sales|  3000|         2|   1|         1|         0.0|     0.43|\n",
       "|   Wayne|     Sales|  3000|         3|   1|         1|         0.0|     0.43|\n",
       "|   Harry|     Sales|  3500|         4|   4|         2|         0.5|     0.57|\n",
       "|  Robert|     Sales|  4100|         5|   5|         3|        0.67|     0.86|\n",
       "|    Saif|     Sales|  4100|         6|   5|         3|        0.67|     0.86|\n",
       "| Michael|     Sales|  4600|         7|   7|         4|         1.0|      1.0|\n",
       "|   Maria|   Finance|  3000|         1|   1|         1|         0.0|     0.33|\n",
       "|   Scott|   Finance|  3300|         2|   2|         2|         0.5|     0.67|\n",
       "|     Jen|   Finance|  3900|         3|   3|         3|         1.0|      1.0|\n",
       "|   Kumar| Marketing|  2000|         1|   1|         1|         0.0|      0.5|\n",
       "|    Jeff| Marketing|  3000|         2|   2|         2|         1.0|      1.0|\n",
       "+--------+----------+------+----------+----+----------+------------+---------+"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\\\n",
    "    .withColumn('row_number', F.row_number().over(window))\\\n",
    "    .withColumn('rank', F.rank().over(window))\\\n",
    "    .withColumn('dense_rank', F.dense_rank().over(window))\\\n",
    "    .withColumn('percent_rank', F.round(F.percent_rank().over(window), 2))\\\n",
    "    .withColumn('cume_dist', F.round(F.cume_dist().over(window), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>employee</th><th>department</th><th>salary</th><th>lag_1</th><th>lead_2</th></tr>\n",
       "<tr><td>James</td><td>Sales</td><td>3000</td><td>null</td><td>3000</td></tr>\n",
       "<tr><td>Ash</td><td>Sales</td><td>3000</td><td>3000</td><td>3500</td></tr>\n",
       "<tr><td>Wayne</td><td>Sales</td><td>3000</td><td>3000</td><td>4100</td></tr>\n",
       "<tr><td>Harry</td><td>Sales</td><td>3500</td><td>3000</td><td>4100</td></tr>\n",
       "<tr><td>Robert</td><td>Sales</td><td>4100</td><td>3500</td><td>4600</td></tr>\n",
       "<tr><td>Saif</td><td>Sales</td><td>4100</td><td>4100</td><td>null</td></tr>\n",
       "<tr><td>Michael</td><td>Sales</td><td>4600</td><td>4100</td><td>null</td></tr>\n",
       "<tr><td>Maria</td><td>Finance</td><td>3000</td><td>null</td><td>3900</td></tr>\n",
       "<tr><td>Scott</td><td>Finance</td><td>3300</td><td>3000</td><td>null</td></tr>\n",
       "<tr><td>Jen</td><td>Finance</td><td>3900</td><td>3300</td><td>null</td></tr>\n",
       "<tr><td>Kumar</td><td>Marketing</td><td>2000</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>3000</td><td>2000</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+----------+------+-----+------+\n",
       "|employee|department|salary|lag_1|lead_2|\n",
       "+--------+----------+------+-----+------+\n",
       "|   James|     Sales|  3000| null|  3000|\n",
       "|     Ash|     Sales|  3000| 3000|  3500|\n",
       "|   Wayne|     Sales|  3000| 3000|  4100|\n",
       "|   Harry|     Sales|  3500| 3000|  4100|\n",
       "|  Robert|     Sales|  4100| 3500|  4600|\n",
       "|    Saif|     Sales|  4100| 4100|  null|\n",
       "| Michael|     Sales|  4600| 4100|  null|\n",
       "|   Maria|   Finance|  3000| null|  3900|\n",
       "|   Scott|   Finance|  3300| 3000|  null|\n",
       "|     Jen|   Finance|  3900| 3300|  null|\n",
       "|   Kumar| Marketing|  2000| null|  null|\n",
       "|    Jeff| Marketing|  3000| 2000|  null|\n",
       "+--------+----------+------+-----+------+"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\\\n",
    "    .withColumn('lag_1', F.lag('salary', 1).over(window))\\\n",
    "    .withColumn('lead_2', F.lead('salary', 2).over(window))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>employee</th><th>department</th><th>salary</th><th>cumsum</th></tr>\n",
       "<tr><td>James</td><td>Sales</td><td>3000</td><td>9000</td></tr>\n",
       "<tr><td>Ash</td><td>Sales</td><td>3000</td><td>9000</td></tr>\n",
       "<tr><td>Wayne</td><td>Sales</td><td>3000</td><td>9000</td></tr>\n",
       "<tr><td>Harry</td><td>Sales</td><td>3500</td><td>12500</td></tr>\n",
       "<tr><td>Robert</td><td>Sales</td><td>4100</td><td>20700</td></tr>\n",
       "<tr><td>Saif</td><td>Sales</td><td>4100</td><td>20700</td></tr>\n",
       "<tr><td>Michael</td><td>Sales</td><td>4600</td><td>25300</td></tr>\n",
       "<tr><td>Maria</td><td>Finance</td><td>3000</td><td>3000</td></tr>\n",
       "<tr><td>Scott</td><td>Finance</td><td>3300</td><td>6300</td></tr>\n",
       "<tr><td>Jen</td><td>Finance</td><td>3900</td><td>10200</td></tr>\n",
       "<tr><td>Kumar</td><td>Marketing</td><td>2000</td><td>2000</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>3000</td><td>5000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+----------+------+------+\n",
       "|employee|department|salary|cumsum|\n",
       "+--------+----------+------+------+\n",
       "|   James|     Sales|  3000|  9000|\n",
       "|     Ash|     Sales|  3000|  9000|\n",
       "|   Wayne|     Sales|  3000|  9000|\n",
       "|   Harry|     Sales|  3500| 12500|\n",
       "|  Robert|     Sales|  4100| 20700|\n",
       "|    Saif|     Sales|  4100| 20700|\n",
       "| Michael|     Sales|  4600| 25300|\n",
       "|   Maria|   Finance|  3000|  3000|\n",
       "|   Scott|   Finance|  3300|  6300|\n",
       "|     Jen|   Finance|  3900| 10200|\n",
       "|   Kumar| Marketing|  2000|  2000|\n",
       "|    Jeff| Marketing|  3000|  5000|\n",
       "+--------+----------+------+------+"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\\\n",
    "    .withColumn('cumsum', F.sum('salary').over(window))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Unpivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>color</th><th>small</th><th>medium</th><th>large</th></tr>\n",
       "<tr><td>red</td><td>1000</td><td>1200</td><td>1500</td></tr>\n",
       "<tr><td>green</td><td>1500</td><td>1500</td><td>1575</td></tr>\n",
       "<tr><td>blue</td><td>2000</td><td>2200</td><td>2000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+-----+------+-----+\n",
       "|color|small|medium|large|\n",
       "+-----+-----+------+-----+\n",
       "|  red| 1000|  1200| 1500|\n",
       "|green| 1500|  1500| 1575|\n",
       "| blue| 2000|  2200| 2000|\n",
       "+-----+-----+------+-----+"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    ('red', 1000, 1200, 1500),\n",
    "    ('green', 1500, 1500, 1575),\n",
    "    ('blue', 2000, 2200, 2000)\n",
    ")\n",
    "\n",
    "columns = ['color', 'small', 'medium', 'large']\n",
    "\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>color</th><th>size</th><th>price</th></tr>\n",
       "<tr><td>red</td><td>small</td><td>1000</td></tr>\n",
       "<tr><td>red</td><td>medium</td><td>1200</td></tr>\n",
       "<tr><td>red</td><td>large</td><td>1500</td></tr>\n",
       "<tr><td>green</td><td>small</td><td>1500</td></tr>\n",
       "<tr><td>green</td><td>medium</td><td>1500</td></tr>\n",
       "<tr><td>green</td><td>large</td><td>1575</td></tr>\n",
       "<tr><td>blue</td><td>small</td><td>2000</td></tr>\n",
       "<tr><td>blue</td><td>medium</td><td>2200</td></tr>\n",
       "<tr><td>blue</td><td>large</td><td>2000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+------+-----+\n",
       "|color|  size|price|\n",
       "+-----+------+-----+\n",
       "|  red| small| 1000|\n",
       "|  red|medium| 1200|\n",
       "|  red| large| 1500|\n",
       "|green| small| 1500|\n",
       "|green|medium| 1500|\n",
       "|green| large| 1575|\n",
       "| blue| small| 2000|\n",
       "| blue|medium| 2200|\n",
       "| blue| large| 2000|\n",
       "+-----+------+-----+"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('color', F.expr('stack(3, \"small\", small, \"medium\", medium, \"large\", large) as (size, price)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>invoice_id</th><th>brand</th><th>city</th><th>customer_type</th><th>gender</th><th>product_line</th><th>unit_price</th><th>quantity</th><th>tax</th><th>date</th><th>time</th><th>payment</th><th>cost</th><th>gross_margin_percentage</th><th>profit</th><th>rating</th></tr>\n",
       "<tr><td>750-67-8428</td><td>A</td><td>Yangon</td><td>Member</td><td>Female</td><td>Health and beauty</td><td>74.69</td><td>7</td><td>26.1415</td><td>01/05/2019</td><td>13:08</td><td>Ewallet</td><td>522.83</td><td>4.761904762</td><td>26.1415</td><td>9.1</td></tr>\n",
       "<tr><td>226-31-3081</td><td>C</td><td>Naypyitaw</td><td>Normal</td><td>Female</td><td>Electronic access...</td><td>15.28</td><td>5</td><td>3.82</td><td>03/08/2019</td><td>10:29</td><td>Cash</td><td>76.4</td><td>4.761904762</td><td>3.82</td><td>9.6</td></tr>\n",
       "<tr><td>631-41-3108</td><td>A</td><td>Yangon</td><td>Normal</td><td>Male</td><td>Home and lifestyle</td><td>46.33</td><td>7</td><td>16.2155</td><td>03/03/2019</td><td>13:23</td><td>Credit card</td><td>324.31</td><td>4.761904762</td><td>16.2155</td><td>7.4</td></tr>\n",
       "<tr><td>123-19-1176</td><td>A</td><td>Yangon</td><td>Member</td><td>Male</td><td>Health and beauty</td><td>58.22</td><td>8</td><td>23.288</td><td>1/27/2019</td><td>20:33</td><td>Ewallet</td><td>465.76</td><td>4.761904762</td><td>23.288</td><td>8.4</td></tr>\n",
       "<tr><td>373-73-7910</td><td>A</td><td>Yangon</td><td>Normal</td><td>Male</td><td>Sports and travel</td><td>86.31</td><td>7</td><td>30.2085</td><td>02/08/2019</td><td>10:37</td><td>Ewallet</td><td>604.17</td><td>4.761904762</td><td>30.2085</td><td>5.3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+\n",
       "| invoice_id|brand|     city|customer_type|gender|        product_line|unit_price|quantity|    tax|      date| time|    payment|  cost|gross_margin_percentage| profit|rating|\n",
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+\n",
       "|750-67-8428|    A|   Yangon|       Member|Female|   Health and beauty|     74.69|       7|26.1415|01/05/2019|13:08|    Ewallet|522.83|            4.761904762|26.1415|   9.1|\n",
       "|226-31-3081|    C|Naypyitaw|       Normal|Female|Electronic access...|     15.28|       5|   3.82|03/08/2019|10:29|       Cash|  76.4|            4.761904762|   3.82|   9.6|\n",
       "|631-41-3108|    A|   Yangon|       Normal|  Male|  Home and lifestyle|     46.33|       7|16.2155|03/03/2019|13:23|Credit card|324.31|            4.761904762|16.2155|   7.4|\n",
       "|123-19-1176|    A|   Yangon|       Member|  Male|   Health and beauty|     58.22|       8| 23.288| 1/27/2019|20:33|    Ewallet|465.76|            4.761904762| 23.288|   8.4|\n",
       "|373-73-7910|    A|   Yangon|       Normal|  Male|   Sports and travel|     86.31|       7|30.2085|02/08/2019|10:37|    Ewallet|604.17|            4.761904762|30.2085|   5.3|\n",
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supermarket = spark.read.csv(r'data\\supermarket_sales.csv', header=True)\n",
    "supermarket.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product_line</th><th>Mandalay</th><th>Naypyitaw</th><th>Yangon</th></tr>\n",
       "<tr><td>Home and lifestyle</td><td>16.71</td><td>14.7</td><td>16.42</td></tr>\n",
       "<tr><td>Fashion accessories</td><td>12.61</td><td>15.79</td><td>15.25</td></tr>\n",
       "<tr><td>Health and beauty</td><td>17.95</td><td>15.22</td><td>12.76</td></tr>\n",
       "<tr><td>Electronic access...</td><td>14.76</td><td>16.42</td><td>14.54</td></tr>\n",
       "<tr><td>Food and beverages</td><td>14.49</td><td>17.15</td><td>14.09</td></tr>\n",
       "<tr><td>Sports and travel</td><td>15.35</td><td>16.68</td><td>15.64</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+--------+---------+------+\n",
       "|        product_line|Mandalay|Naypyitaw|Yangon|\n",
       "+--------------------+--------+---------+------+\n",
       "|  Home and lifestyle|   16.71|     14.7| 16.42|\n",
       "| Fashion accessories|   12.61|    15.79| 15.25|\n",
       "|   Health and beauty|   17.95|    15.22| 12.76|\n",
       "|Electronic access...|   14.76|    16.42| 14.54|\n",
       "|  Food and beverages|   14.49|    17.15| 14.09|\n",
       "|   Sports and travel|   15.35|    16.68| 15.64|\n",
       "+--------------------+--------+---------+------+"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supermarket\\\n",
    "    .groupBy('product_line')\\\n",
    "    .pivot('city')\\\n",
    "    .agg(F.round(F.mean('profit'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product_line</th><th>Female, Member</th><th>Female, Normal</th><th>Male, Member</th><th>Male, Normal</th></tr>\n",
       "<tr><td>Home and lifestyle</td><td>17.46</td><td>19.05</td><td>14.21</td><td>13.84</td></tr>\n",
       "<tr><td>Fashion accessories</td><td>15.32</td><td>14.88</td><td>13.68</td><td>14.03</td></tr>\n",
       "<tr><td>Health and beauty</td><td>13.3</td><td>14.26</td><td>19.33</td><td>13.95</td></tr>\n",
       "<tr><td>Electronic access...</td><td>15.17</td><td>15.5</td><td>14.78</td><td>15.38</td></tr>\n",
       "<tr><td>Food and beverages</td><td>18.3</td><td>16.57</td><td>13.02</td><td>13.03</td></tr>\n",
       "<tr><td>Sports and travel</td><td>15.55</td><td>15.34</td><td>15.31</td><td>16.98</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+--------------+--------------+------------+------------+\n",
       "|        product_line|Female, Member|Female, Normal|Male, Member|Male, Normal|\n",
       "+--------------------+--------------+--------------+------------+------------+\n",
       "|  Home and lifestyle|         17.46|         19.05|       14.21|       13.84|\n",
       "| Fashion accessories|         15.32|         14.88|       13.68|       14.03|\n",
       "|   Health and beauty|          13.3|         14.26|       19.33|       13.95|\n",
       "|Electronic access...|         15.17|          15.5|       14.78|       15.38|\n",
       "|  Food and beverages|          18.3|         16.57|       13.02|       13.03|\n",
       "|   Sports and travel|         15.55|         15.34|       15.31|       16.98|\n",
       "+--------------------+--------------+--------------+------------+------------+"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supermarket\\\n",
    "    .withColumn('info', F.concat(F.col('gender'), F.lit(', '), F.col('customer_type')))\\\n",
    "    .groupBy('product_line')\\\n",
    "    .pivot('info')\\\n",
    "    .agg(F.round(F.mean('profit'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Crosstab\n",
    "Crosstab is a special case of pivot table, where `count` is selected as the aggregate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>invoice_id</th><th>brand</th><th>city</th><th>customer_type</th><th>gender</th><th>product_line</th><th>unit_price</th><th>quantity</th><th>tax</th><th>date</th><th>time</th><th>payment</th><th>cost</th><th>gross_margin_percentage</th><th>profit</th><th>rating</th></tr>\n",
       "<tr><td>750-67-8428</td><td>A</td><td>Yangon</td><td>Member</td><td>Female</td><td>Health and beauty</td><td>74.69</td><td>7</td><td>26.1415</td><td>01/05/2019</td><td>13:08</td><td>Ewallet</td><td>522.83</td><td>4.761904762</td><td>26.1415</td><td>9.1</td></tr>\n",
       "<tr><td>226-31-3081</td><td>C</td><td>Naypyitaw</td><td>Normal</td><td>Female</td><td>Electronic access...</td><td>15.28</td><td>5</td><td>3.82</td><td>03/08/2019</td><td>10:29</td><td>Cash</td><td>76.4</td><td>4.761904762</td><td>3.82</td><td>9.6</td></tr>\n",
       "<tr><td>631-41-3108</td><td>A</td><td>Yangon</td><td>Normal</td><td>Male</td><td>Home and lifestyle</td><td>46.33</td><td>7</td><td>16.2155</td><td>03/03/2019</td><td>13:23</td><td>Credit card</td><td>324.31</td><td>4.761904762</td><td>16.2155</td><td>7.4</td></tr>\n",
       "<tr><td>123-19-1176</td><td>A</td><td>Yangon</td><td>Member</td><td>Male</td><td>Health and beauty</td><td>58.22</td><td>8</td><td>23.288</td><td>1/27/2019</td><td>20:33</td><td>Ewallet</td><td>465.76</td><td>4.761904762</td><td>23.288</td><td>8.4</td></tr>\n",
       "<tr><td>373-73-7910</td><td>A</td><td>Yangon</td><td>Normal</td><td>Male</td><td>Sports and travel</td><td>86.31</td><td>7</td><td>30.2085</td><td>02/08/2019</td><td>10:37</td><td>Ewallet</td><td>604.17</td><td>4.761904762</td><td>30.2085</td><td>5.3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+\n",
       "| invoice_id|brand|     city|customer_type|gender|        product_line|unit_price|quantity|    tax|      date| time|    payment|  cost|gross_margin_percentage| profit|rating|\n",
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+\n",
       "|750-67-8428|    A|   Yangon|       Member|Female|   Health and beauty|     74.69|       7|26.1415|01/05/2019|13:08|    Ewallet|522.83|            4.761904762|26.1415|   9.1|\n",
       "|226-31-3081|    C|Naypyitaw|       Normal|Female|Electronic access...|     15.28|       5|   3.82|03/08/2019|10:29|       Cash|  76.4|            4.761904762|   3.82|   9.6|\n",
       "|631-41-3108|    A|   Yangon|       Normal|  Male|  Home and lifestyle|     46.33|       7|16.2155|03/03/2019|13:23|Credit card|324.31|            4.761904762|16.2155|   7.4|\n",
       "|123-19-1176|    A|   Yangon|       Member|  Male|   Health and beauty|     58.22|       8| 23.288| 1/27/2019|20:33|    Ewallet|465.76|            4.761904762| 23.288|   8.4|\n",
       "|373-73-7910|    A|   Yangon|       Normal|  Male|   Sports and travel|     86.31|       7|30.2085|02/08/2019|10:37|    Ewallet|604.17|            4.761904762|30.2085|   5.3|\n",
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supermarket = spark.read.csv(r'data\\supermarket_sales.csv', header=True)\n",
    "supermarket.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>city_payment</th><th>Cash</th><th>Credit card</th><th>Ewallet</th></tr>\n",
       "<tr><td>Naypyitaw</td><td>124</td><td>98</td><td>106</td></tr>\n",
       "<tr><td>Mandalay</td><td>110</td><td>109</td><td>113</td></tr>\n",
       "<tr><td>Yangon</td><td>110</td><td>104</td><td>126</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+----+-----------+-------+\n",
       "|city_payment|Cash|Credit card|Ewallet|\n",
       "+------------+----+-----------+-------+\n",
       "|   Naypyitaw| 124|         98|    106|\n",
       "|    Mandalay| 110|        109|    113|\n",
       "|      Yangon| 110|        104|    126|\n",
       "+------------+----+-----------+-------+"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supermarket.crosstab('city', 'payment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Combining datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Union\n",
    "PySpark supports two union methods:\n",
    "- `union`: union using the current order of columns\n",
    "- `unionByName`: union using column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>quarter</th><th>profit</th></tr>\n",
       "<tr><td>2019</td><td>1</td><td>2500</td></tr>\n",
       "<tr><td>2019</td><td>2</td><td>3500</td></tr>\n",
       "<tr><td>2019</td><td>3</td><td>4000</td></tr>\n",
       "<tr><td>2019</td><td>4</td><td>5000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+------+\n",
       "|year|quarter|profit|\n",
       "+----+-------+------+\n",
       "|2019|      1|  2500|\n",
       "|2019|      2|  3500|\n",
       "|2019|      3|  4000|\n",
       "|2019|      4|  5000|\n",
       "+----+-------+------+"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    (2019, 1, 2500),\n",
    "    (2019, 2, 3500),\n",
    "    (2019, 3, 4000),\n",
    "    (2019, 4, 5000)\n",
    ")\n",
    "\n",
    "columns = ['year', 'quarter', 'profit']\n",
    "\n",
    "df_19 = spark.createDataFrame(data, schema=columns)\n",
    "df_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>quarter</th><th>profit</th></tr>\n",
       "<tr><td>2020</td><td>1</td><td>2700</td></tr>\n",
       "<tr><td>2020</td><td>2</td><td>3900</td></tr>\n",
       "<tr><td>2020</td><td>3</td><td>5000</td></tr>\n",
       "<tr><td>2020</td><td>4</td><td>8000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+------+\n",
       "|year|quarter|profit|\n",
       "+----+-------+------+\n",
       "|2020|      1|  2700|\n",
       "|2020|      2|  3900|\n",
       "|2020|      3|  5000|\n",
       "|2020|      4|  8000|\n",
       "+----+-------+------+"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    (2020, 1, 2700),\n",
    "    (2020, 2, 3900),\n",
    "    (2020, 3, 5000),\n",
    "    (2020, 4, 8000)\n",
    ")\n",
    "\n",
    "columns = ['year', 'quarter', 'profit']\n",
    "\n",
    "df_20 = spark.createDataFrame(data, schema=columns)\n",
    "df_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>quarter</th><th>profit</th></tr>\n",
       "<tr><td>2019</td><td>1</td><td>2500</td></tr>\n",
       "<tr><td>2019</td><td>2</td><td>3500</td></tr>\n",
       "<tr><td>2019</td><td>3</td><td>4000</td></tr>\n",
       "<tr><td>2019</td><td>4</td><td>5000</td></tr>\n",
       "<tr><td>2020</td><td>1</td><td>2700</td></tr>\n",
       "<tr><td>2020</td><td>2</td><td>3900</td></tr>\n",
       "<tr><td>2020</td><td>3</td><td>5000</td></tr>\n",
       "<tr><td>2020</td><td>4</td><td>8000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+------+\n",
       "|year|quarter|profit|\n",
       "+----+-------+------+\n",
       "|2019|      1|  2500|\n",
       "|2019|      2|  3500|\n",
       "|2019|      3|  4000|\n",
       "|2019|      4|  5000|\n",
       "|2020|      1|  2700|\n",
       "|2020|      2|  3900|\n",
       "|2020|      3|  5000|\n",
       "|2020|      4|  8000|\n",
       "+----+-------+------+"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_19.union(df_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>quarter</th><th>profit</th></tr>\n",
       "<tr><td>2019</td><td>1</td><td>2500</td></tr>\n",
       "<tr><td>2019</td><td>2</td><td>3500</td></tr>\n",
       "<tr><td>2019</td><td>3</td><td>4000</td></tr>\n",
       "<tr><td>2019</td><td>4</td><td>5000</td></tr>\n",
       "<tr><td>2020</td><td>1</td><td>2700</td></tr>\n",
       "<tr><td>2020</td><td>2</td><td>3900</td></tr>\n",
       "<tr><td>2020</td><td>3</td><td>5000</td></tr>\n",
       "<tr><td>2020</td><td>4</td><td>8000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+------+\n",
       "|year|quarter|profit|\n",
       "+----+-------+------+\n",
       "|2019|      1|  2500|\n",
       "|2019|      2|  3500|\n",
       "|2019|      3|  4000|\n",
       "|2019|      4|  5000|\n",
       "|2020|      1|  2700|\n",
       "|2020|      2|  3900|\n",
       "|2020|      3|  5000|\n",
       "|2020|      4|  8000|\n",
       "+----+-------+------+"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_19.unionByName(df_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>income_before_tax</th><th>tax_band</th></tr>\n",
       "<tr><td>Hannah</td><td>1200</td><td>Allowance</td></tr>\n",
       "<tr><td>James</td><td>3000</td><td>Basic</td></tr>\n",
       "<tr><td>Gabriel</td><td>700</td><td>Allowance</td></tr>\n",
       "<tr><td>Smith</td><td>2000</td><td>Basic</td></tr>\n",
       "<tr><td>Alex</td><td>10000</td><td>Higher</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-----------------+---------+\n",
       "|   name|income_before_tax| tax_band|\n",
       "+-------+-----------------+---------+\n",
       "| Hannah|             1200|Allowance|\n",
       "|  James|             3000|    Basic|\n",
       "|Gabriel|              700|Allowance|\n",
       "|  Smith|             2000|    Basic|\n",
       "|   Alex|            10000|   Higher|\n",
       "+-------+-----------------+---------+"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    ('Hannah', 1200, 'Allowance'),\n",
    "    ('James', 3000, 'Basic'),\n",
    "    ('Gabriel', 700, 'Allowance'),\n",
    "    ('Smith', 2000, 'Basic'),\n",
    "    ('Alex', 10000, 'Higher'),\n",
    ")\n",
    "\n",
    "columns = ['name', 'income_before_tax', 'tax_band']\n",
    "\n",
    "income = spark.createDataFrame(data, schema=columns)\n",
    "income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>band</th><th>income_range</th><th>tax_rate</th></tr>\n",
       "<tr><td>Allowance</td><td>Up to 12,500</td><td>0.0</td></tr>\n",
       "<tr><td>Basic</td><td>12,501 to 50,000</td><td>0.2</td></tr>\n",
       "<tr><td>Higher</td><td>50,001 to 150,000</td><td>0.4</td></tr>\n",
       "<tr><td>Additional</td><td>Over 150,000</td><td>0.45</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+-----------------+--------+\n",
       "|      band|     income_range|tax_rate|\n",
       "+----------+-----------------+--------+\n",
       "| Allowance|     Up to 12,500|     0.0|\n",
       "|     Basic| 12,501 to 50,000|     0.2|\n",
       "|    Higher|50,001 to 150,000|     0.4|\n",
       "|Additional|     Over 150,000|    0.45|\n",
       "+----------+-----------------+--------+"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    ('Allowance', 'Up to 12,500', 0.0),\n",
    "    ('Basic', '12,501 to 50,000', 0.2),\n",
    "    ('Higher', '50,001 to 150,000', 0.4),\n",
    "    ('Additional', 'Over 150,000', 0.45),\n",
    ")\n",
    "\n",
    "columns = ['band', 'income_range', 'tax_rate']\n",
    "\n",
    "tax = spark.createDataFrame(data, columns)\n",
    "tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>income_before_tax</th><th>tax_band</th><th>band</th><th>income_range</th><th>tax_rate</th></tr>\n",
       "<tr><td>Hannah</td><td>1200</td><td>Allowance</td><td>Allowance</td><td>Up to 12,500</td><td>0.0</td></tr>\n",
       "<tr><td>Gabriel</td><td>700</td><td>Allowance</td><td>Allowance</td><td>Up to 12,500</td><td>0.0</td></tr>\n",
       "<tr><td>Alex</td><td>10000</td><td>Higher</td><td>Higher</td><td>50,001 to 150,000</td><td>0.4</td></tr>\n",
       "<tr><td>James</td><td>3000</td><td>Basic</td><td>Basic</td><td>12,501 to 50,000</td><td>0.2</td></tr>\n",
       "<tr><td>Smith</td><td>2000</td><td>Basic</td><td>Basic</td><td>12,501 to 50,000</td><td>0.2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-----------------+---------+---------+-----------------+--------+\n",
       "|   name|income_before_tax| tax_band|     band|     income_range|tax_rate|\n",
       "+-------+-----------------+---------+---------+-----------------+--------+\n",
       "| Hannah|             1200|Allowance|Allowance|     Up to 12,500|     0.0|\n",
       "|Gabriel|              700|Allowance|Allowance|     Up to 12,500|     0.0|\n",
       "|   Alex|            10000|   Higher|   Higher|50,001 to 150,000|     0.4|\n",
       "|  James|             3000|    Basic|    Basic| 12,501 to 50,000|     0.2|\n",
       "|  Smith|             2000|    Basic|    Basic| 12,501 to 50,000|     0.2|\n",
       "+-------+-----------------+---------+---------+-----------------+--------+"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income.join(tax, income.tax_band==tax.band, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>band</th><th>name</th><th>income_before_tax</th><th>income_range</th><th>tax_rate</th></tr>\n",
       "<tr><td>Allowance</td><td>Hannah</td><td>1200</td><td>Up to 12,500</td><td>0.0</td></tr>\n",
       "<tr><td>Allowance</td><td>Gabriel</td><td>700</td><td>Up to 12,500</td><td>0.0</td></tr>\n",
       "<tr><td>Higher</td><td>Alex</td><td>10000</td><td>50,001 to 150,000</td><td>0.4</td></tr>\n",
       "<tr><td>Basic</td><td>James</td><td>3000</td><td>12,501 to 50,000</td><td>0.2</td></tr>\n",
       "<tr><td>Basic</td><td>Smith</td><td>2000</td><td>12,501 to 50,000</td><td>0.2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+-------+-----------------+-----------------+--------+\n",
       "|     band|   name|income_before_tax|     income_range|tax_rate|\n",
       "+---------+-------+-----------------+-----------------+--------+\n",
       "|Allowance| Hannah|             1200|     Up to 12,500|     0.0|\n",
       "|Allowance|Gabriel|              700|     Up to 12,500|     0.0|\n",
       "|   Higher|   Alex|            10000|50,001 to 150,000|     0.4|\n",
       "|    Basic|  James|             3000| 12,501 to 50,000|     0.2|\n",
       "|    Basic|  Smith|             2000| 12,501 to 50,000|     0.2|\n",
       "+---------+-------+-----------------+-----------------+--------+"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income\\\n",
    "    .withColumnRenamed('tax_band', 'band')\\\n",
    "    .join(tax, on='band', how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
