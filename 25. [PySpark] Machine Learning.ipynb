{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification\n",
    "Classfication algorithms in PySpark require labels to be numeric. String labels can be transformed into float using the `StringIndexer` function or using mapping technique. In binary classification, label 1 is treated as the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, DecisionTreeClassificationModel\n",
    "from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\n",
    "from pyspark.ml.classification import GBTClassifier, GBTClassificationModel\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier, MultilayerPerceptronClassificationModel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>sepal_length</th><th>sepal_width</th><th>petal_length</th><th>petal_width</th><th>species</th><th>species_index</th></tr>\n",
       "<tr><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td><td>setosa</td><td>0.0</td></tr>\n",
       "<tr><td>4.9</td><td>3.0</td><td>1.4</td><td>0.2</td><td>setosa</td><td>0.0</td></tr>\n",
       "<tr><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td><td>setosa</td><td>0.0</td></tr>\n",
       "<tr><td>4.6</td><td>3.1</td><td>1.5</td><td>0.2</td><td>setosa</td><td>0.0</td></tr>\n",
       "<tr><td>5.0</td><td>3.6</td><td>1.4</td><td>0.2</td><td>setosa</td><td>0.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+-----------+------------+-----------+-------+-------------+\n",
       "|sepal_length|sepal_width|petal_length|petal_width|species|species_index|\n",
       "+------------+-----------+------------+-----------+-------+-------------+\n",
       "|         5.1|        3.5|         1.4|        0.2| setosa|          0.0|\n",
       "|         4.9|        3.0|         1.4|        0.2| setosa|          0.0|\n",
       "|         4.7|        3.2|         1.3|        0.2| setosa|          0.0|\n",
       "|         4.6|        3.1|         1.5|        0.2| setosa|          0.0|\n",
       "|         5.0|        3.6|         1.4|        0.2| setosa|          0.0|\n",
       "+------------+-----------+------------+-----------+-------+-------------+"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = spark.read.csv(r'data\\iris.csv', header=True)\n",
    "for i in ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']:\n",
    "    iris = iris.withColumn(i, F.col(i).cast('float'))\n",
    "indexer = StringIndexer(inputCol='species', outputCol='species_index')\n",
    "iris = indexer.fit(iris).transform(iris)\n",
    "iris.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>features</th><th>label</th></tr>\n",
       "<tr><td>[5.09999990463256...</td><td>0.0</td></tr>\n",
       "<tr><td>[4.90000009536743...</td><td>0.0</td></tr>\n",
       "<tr><td>[4.69999980926513...</td><td>0.0</td></tr>\n",
       "<tr><td>[4.59999990463256...</td><td>0.0</td></tr>\n",
       "<tr><td>[5.0,3.5999999046...</td><td>0.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+-----+\n",
       "|            features|label|\n",
       "+--------------------+-----+\n",
       "|[5.09999990463256...|  0.0|\n",
       "|[4.90000009536743...|  0.0|\n",
       "|[4.69999980926513...|  0.0|\n",
       "|[4.59999990463256...|  0.0|\n",
       "|[5.0,3.5999999046...|  0.0|\n",
       "+--------------------+-----+"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "label = 'species_index'\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "\n",
    "iris = assembler.transform(iris)\n",
    "iris = iris.selectExpr('features', 'species_index AS label')\n",
    "iris.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_train, iris_test = iris.randomSplit([0.8, 0.2], seed=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "*Reference: [PySpark - Naive Bayes](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.NaiveBayes.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = NaiveBayes(\n",
    "    modelType='gaussian',\n",
    "    smoothing=0.1\n",
    ")\n",
    "\n",
    "model = bayes.fit(iris_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>features</th><th>label</th><th>rawPrediction</th><th>probability</th><th>prediction</th></tr>\n",
       "<tr><td>[4.59999990463256...</td><td>0.0</td><td>[4.11081256251336...</td><td>[1.0,4.5682062915...</td><td>0.0</td></tr>\n",
       "<tr><td>[5.0,3.2999999523...</td><td>0.0</td><td>[4.69678632396601...</td><td>[1.0,1.2333989906...</td><td>0.0</td></tr>\n",
       "<tr><td>[5.0,3.5999999046...</td><td>0.0</td><td>[4.60606070445828...</td><td>[1.0,1.3255041009...</td><td>0.0</td></tr>\n",
       "<tr><td>[5.19999980926513...</td><td>0.0</td><td>[2.06201152614811...</td><td>[1.0,8.6079890489...</td><td>0.0</td></tr>\n",
       "<tr><td>[5.40000009536743...</td><td>0.0</td><td>[3.85935042111834...</td><td>[1.0,8.7870105216...</td><td>0.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+-----+--------------------+--------------------+----------+\n",
       "|            features|label|       rawPrediction|         probability|prediction|\n",
       "+--------------------+-----+--------------------+--------------------+----------+\n",
       "|[4.59999990463256...|  0.0|[4.11081256251336...|[1.0,4.5682062915...|       0.0|\n",
       "|[5.0,3.2999999523...|  0.0|[4.69678632396601...|[1.0,1.2333989906...|       0.0|\n",
       "|[5.0,3.5999999046...|  0.0|[4.60606070445828...|[1.0,1.3255041009...|       0.0|\n",
       "|[5.19999980926513...|  0.0|[2.06201152614811...|[1.0,8.6079890489...|       0.0|\n",
       "|[5.40000009536743...|  0.0|[3.85935042111834...|[1.0,8.7870105216...|       0.0|\n",
       "+--------------------+-----+--------------------+--------------------+----------+"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = model.transform(iris_test)\n",
    "predictor.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>&lt;lambda&gt;(probability)</th></tr>\n",
       "<tr><td>1.0</td></tr>\n",
       "<tr><td>1.0</td></tr>\n",
       "<tr><td>1.0</td></tr>\n",
       "<tr><td>1.0</td></tr>\n",
       "<tr><td>1.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------------+\n",
       "|<lambda>(probability)|\n",
       "+---------------------+\n",
       "|                  1.0|\n",
       "|                  1.0|\n",
       "|                  1.0|\n",
       "|                  1.0|\n",
       "|                  1.0|\n",
       "+---------------------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getItem = F.udf(lambda col: float(col[0]), T.FloatType())\n",
    "predictor.select(getItem('probability')).limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "*Reference: [PySpark - Logistic Regression](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.LogisticRegression.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(\n",
    "    elasticNetParam=0.5,\n",
    "    regParam=0.1\n",
    ")\n",
    "\n",
    "model = logistic.fit(iris_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>features</th><th>label</th><th>rawPrediction</th><th>probability</th><th>prediction</th></tr>\n",
       "<tr><td>[4.59999990463256...</td><td>0.0</td><td>[2.11777964128874...</td><td>[0.86270648434772...</td><td>0.0</td></tr>\n",
       "<tr><td>[5.0,3.2999999523...</td><td>0.0</td><td>[2.01546198803795...</td><td>[0.84580574303289...</td><td>0.0</td></tr>\n",
       "<tr><td>[5.0,3.5999999046...</td><td>0.0</td><td>[2.26626426475033...</td><td>[0.88805604538443...</td><td>0.0</td></tr>\n",
       "<tr><td>[5.19999980926513...</td><td>0.0</td><td>[2.67738960744594...</td><td>[0.93589969409573...</td><td>0.0</td></tr>\n",
       "<tr><td>[5.40000009536743...</td><td>0.0</td><td>[2.20083593390341...</td><td>[0.88455758657283...</td><td>0.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+-----+--------------------+--------------------+----------+\n",
       "|            features|label|       rawPrediction|         probability|prediction|\n",
       "+--------------------+-----+--------------------+--------------------+----------+\n",
       "|[4.59999990463256...|  0.0|[2.11777964128874...|[0.86270648434772...|       0.0|\n",
       "|[5.0,3.2999999523...|  0.0|[2.01546198803795...|[0.84580574303289...|       0.0|\n",
       "|[5.0,3.5999999046...|  0.0|[2.26626426475033...|[0.88805604538443...|       0.0|\n",
       "|[5.19999980926513...|  0.0|[2.67738960744594...|[0.93589969409573...|       0.0|\n",
       "|[5.40000009536743...|  0.0|[2.20083593390341...|[0.88455758657283...|       0.0|\n",
       "+--------------------+-----+--------------------+--------------------+----------+"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = model.transform(iris_test)\n",
    "predictor.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "*Reference: [PySpark - Decision Tree](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.DecisionTreeClassifier.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(\n",
    "    impurity='entropy',\n",
    "    maxDepth=8,\n",
    "    maxBins=16,\n",
    "    minInstancesPerNode=10,\n",
    "    minInfoGain=0.1,\n",
    "    minWeightFractionPerNode=0.2,\n",
    ")\n",
    "model = tree.fit(iris_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "*Reference: [PySpark - Random Forest](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.RandomForestClassifier.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(\n",
    "    impurity='entropy',\n",
    "    maxDepth=8,\n",
    "    maxBins=16,\n",
    "    minInstancesPerNode=10,\n",
    "    minInfoGain=0.1,\n",
    "    minWeightFractionPerNode=0.2,\n",
    "    \n",
    "    numTrees=32,\n",
    "    featureSubsetStrategy='sqrt',\n",
    "    subsamplingRate=0.8\n",
    ")\n",
    "model = forest.fit(iris_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees\n",
    "`GBTClassifier` currently only supports binary classification.\n",
    "\n",
    "*Reference: [PySpark - Gradient Boosted Trees](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.GBTClassifier.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(\n",
    "    impurity='variance',\n",
    "    maxDepth=8,\n",
    "    maxBins=16,\n",
    "    minInstancesPerNode=10,\n",
    "    minInfoGain=0.1,\n",
    "    minWeightFractionPerNode=0.2,\n",
    "    \n",
    "    lossType='logistic',\n",
    "    stepSize=0.1,\n",
    "    featureSubsetStrategy='all'\n",
    ")\n",
    "model = gbt.fit(iris_train.filter('y IN (0.0, 1.0)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilayer Perceptron\n",
    "*Reference: [PySpark - Multilayer Perceptron](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.MultilayerPerceptronClassifier.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MultilayerPerceptronClassifier(\n",
    "    layers=[4, 20, 10, 3],\n",
    "    stepSize=0.03,\n",
    "    tol=1e-6,\n",
    "    solver='l-bfgs'\n",
    ")\n",
    "model = mlp.fit(iris_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, LinearRegressionModel\n",
    "from pyspark.ml.regression import RandomForestRegressor, RandomForestRegressionModel\n",
    "from pyspark.ml.regression import GBTRegressor, GBTRegressionModel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>crime_rate</th><th>land_rate</th><th>indus</th><th>chas</th><th>nox</th><th>room</th><th>age</th><th>distance</th><th>radial</th><th>tax</th><th>ptratio</th><th>black</th><th>lstat</th><th>price</th></tr>\n",
       "<tr><td>0.00632</td><td>18.0</td><td>2.31</td><td>0.0</td><td>0.538</td><td>6.575</td><td>65.2</td><td>4.09</td><td>1.0</td><td>296.0</td><td>15.3</td><td>396.9</td><td>4.98</td><td>24.0</td></tr>\n",
       "<tr><td>0.02731</td><td>0.0</td><td>7.07</td><td>0.0</td><td>0.469</td><td>6.421</td><td>78.9</td><td>4.9671</td><td>2.0</td><td>242.0</td><td>17.8</td><td>396.9</td><td>9.14</td><td>21.6</td></tr>\n",
       "<tr><td>0.02729</td><td>0.0</td><td>7.07</td><td>0.0</td><td>0.469</td><td>7.185</td><td>61.1</td><td>4.9671</td><td>2.0</td><td>242.0</td><td>17.8</td><td>392.83</td><td>4.03</td><td>34.7</td></tr>\n",
       "<tr><td>0.03237</td><td>0.0</td><td>2.18</td><td>0.0</td><td>0.458</td><td>6.998</td><td>45.8</td><td>6.0622</td><td>3.0</td><td>222.0</td><td>18.7</td><td>394.63</td><td>2.94</td><td>33.4</td></tr>\n",
       "<tr><td>0.06905</td><td>0.0</td><td>2.18</td><td>0.0</td><td>0.458</td><td>7.147</td><td>54.2</td><td>6.0622</td><td>3.0</td><td>222.0</td><td>18.7</td><td>396.9</td><td>5.33</td><td>36.2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+---------+-----+----+-----+-----+----+--------+------+-----+-------+------+-----+-----+\n",
       "|crime_rate|land_rate|indus|chas|  nox| room| age|distance|radial|  tax|ptratio| black|lstat|price|\n",
       "+----------+---------+-----+----+-----+-----+----+--------+------+-----+-------+------+-----+-----+\n",
       "|   0.00632|     18.0| 2.31| 0.0|0.538|6.575|65.2|    4.09|   1.0|296.0|   15.3| 396.9| 4.98| 24.0|\n",
       "|   0.02731|      0.0| 7.07| 0.0|0.469|6.421|78.9|  4.9671|   2.0|242.0|   17.8| 396.9| 9.14| 21.6|\n",
       "|   0.02729|      0.0| 7.07| 0.0|0.469|7.185|61.1|  4.9671|   2.0|242.0|   17.8|392.83| 4.03| 34.7|\n",
       "|   0.03237|      0.0| 2.18| 0.0|0.458|6.998|45.8|  6.0622|   3.0|222.0|   18.7|394.63| 2.94| 33.4|\n",
       "|   0.06905|      0.0| 2.18| 0.0|0.458|7.147|54.2|  6.0622|   3.0|222.0|   18.7| 396.9| 5.33| 36.2|\n",
       "+----------+---------+-----+----+-----+-----+----+--------+------+-----+-------+------+-----+-----+"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = spark.read.csv(r'data\\boston.csv', header=True)\n",
    "boston = boston.select([F.col(c).cast('float') for c in boston.columns])\n",
    "boston.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>features</th><th>label</th></tr>\n",
       "<tr><td>[0.00632000016048...</td><td>24.0</td></tr>\n",
       "<tr><td>[0.02731000073254...</td><td>21.6</td></tr>\n",
       "<tr><td>[0.02728999964892...</td><td>34.7</td></tr>\n",
       "<tr><td>[0.03237000107765...</td><td>33.4</td></tr>\n",
       "<tr><td>[0.06904999911785...</td><td>36.2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+-----+\n",
       "|            features|label|\n",
       "+--------------------+-----+\n",
       "|[0.00632000016048...| 24.0|\n",
       "|[0.02731000073254...| 21.6|\n",
       "|[0.02728999964892...| 34.7|\n",
       "|[0.03237000107765...| 33.4|\n",
       "|[0.06904999911785...| 36.2|\n",
       "+--------------------+-----+"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = boston.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "\n",
    "boston = assembler.transform(boston)\n",
    "boston = boston.selectExpr('features', 'price AS label')\n",
    "boston.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_train, boston_test = boston.randomSplit([0.8, 0.2], seed=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "*Reference: [PySpark - Linear Regression](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression(\n",
    "    elasticNetParam=0.5,\n",
    "    regParam=1e-2\n",
    ")\n",
    "\n",
    "model = linear.fit(boston_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>features</th><th>label</th><th>prediction</th></tr>\n",
       "<tr><td>[0.01360000018030...</td><td>18.9</td><td>16.284435700454623</td></tr>\n",
       "<tr><td>[0.01432000007480...</td><td>31.6</td><td>34.06102709920108</td></tr>\n",
       "<tr><td>[0.01501000020653...</td><td>24.5</td><td>28.233316931571785</td></tr>\n",
       "<tr><td>[0.01501000020653...</td><td>50.0</td><td>44.10315078135267</td></tr>\n",
       "<tr><td>[0.01869999989867...</td><td>23.1</td><td>26.167508650667223</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+-----+------------------+\n",
       "|            features|label|        prediction|\n",
       "+--------------------+-----+------------------+\n",
       "|[0.01360000018030...| 18.9|16.284435700454623|\n",
       "|[0.01432000007480...| 31.6| 34.06102709920108|\n",
       "|[0.01501000020653...| 24.5|28.233316931571785|\n",
       "|[0.01501000020653...| 50.0| 44.10315078135267|\n",
       "|[0.01869999989867...| 23.1|26.167508650667223|\n",
       "+--------------------+-----+------------------+"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(boston_test).limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "*Reference: [PySpark - Random Forest Regressor](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.RandomForestRegressor.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(\n",
    "    impurity='variance',\n",
    "    maxDepth=8,\n",
    "    maxBins=16,\n",
    "    minInstancesPerNode=10,\n",
    "    minInfoGain=0.1,\n",
    "    minWeightFractionPerNode=0.2,\n",
    "    \n",
    "    numTrees=32,\n",
    "    featureSubsetStrategy='sqrt',\n",
    "    subsamplingRate=0.8\n",
    ")\n",
    "model = forest.fit(boston_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees\n",
    "*Reference: [PySpark - Gradient Boosted Trees Regressor](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.GBTRegressor.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(    \n",
    "    impurity='variance',\n",
    "    maxDepth=8,\n",
    "    maxBins=16,\n",
    "    minInstancesPerNode=10,\n",
    "    minInfoGain=0.1,\n",
    "    minWeightFractionPerNode=0.2,\n",
    "    \n",
    "    lossType='squared',\n",
    "    stepSize=0.1,\n",
    "    featureSubsetStrategy='all'\n",
    ")\n",
    "model = gbt.fit(boston_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Working on models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\n",
    "from pyspark.ml.classification import GBTClassifier, GBTClassificationModel\n",
    "from pyspark.ml.regression import GBTRegressor, GBTRegressionModel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>sepal_length</th><th>sepal_width</th><th>petal_length</th><th>petal_width</th><th>species</th><th>species_index</th></tr>\n",
       "<tr><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td><td>setosa</td><td>0.0</td></tr>\n",
       "<tr><td>4.9</td><td>3.0</td><td>1.4</td><td>0.2</td><td>setosa</td><td>0.0</td></tr>\n",
       "<tr><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td><td>setosa</td><td>0.0</td></tr>\n",
       "<tr><td>4.6</td><td>3.1</td><td>1.5</td><td>0.2</td><td>setosa</td><td>0.0</td></tr>\n",
       "<tr><td>5.0</td><td>3.6</td><td>1.4</td><td>0.2</td><td>setosa</td><td>0.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+-----------+------------+-----------+-------+-------------+\n",
       "|sepal_length|sepal_width|petal_length|petal_width|species|species_index|\n",
       "+------------+-----------+------------+-----------+-------+-------------+\n",
       "|         5.1|        3.5|         1.4|        0.2| setosa|          0.0|\n",
       "|         4.9|        3.0|         1.4|        0.2| setosa|          0.0|\n",
       "|         4.7|        3.2|         1.3|        0.2| setosa|          0.0|\n",
       "|         4.6|        3.1|         1.5|        0.2| setosa|          0.0|\n",
       "|         5.0|        3.6|         1.4|        0.2| setosa|          0.0|\n",
       "+------------+-----------+------------+-----------+-------+-------------+"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = spark.read.csv(r'data\\iris.csv', header=True)\n",
    "for i in ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']:\n",
    "    iris = iris.withColumn(i, F.col(i).cast('float'))\n",
    "indexer = StringIndexer(inputCol='species', outputCol='species_index')\n",
    "iris = indexer.fit(iris).transform(iris)\n",
    "iris.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "\n",
    "iris = assembler.transform(iris)\n",
    "iris = iris.selectExpr('features', 'CAST(species_index AS int) AS label')\n",
    "iris_train, iris_test = iris.randomSplit([0.8, 0.2], seed=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>crime_rate</th><th>land_rate</th><th>indus</th><th>chas</th><th>nox</th><th>room</th><th>age</th><th>distance</th><th>radial</th><th>tax</th><th>ptratio</th><th>black</th><th>lstat</th><th>price</th></tr>\n",
       "<tr><td>0.00632</td><td>18.0</td><td>2.31</td><td>0.0</td><td>0.538</td><td>6.575</td><td>65.2</td><td>4.09</td><td>1.0</td><td>296.0</td><td>15.3</td><td>396.9</td><td>4.98</td><td>24.0</td></tr>\n",
       "<tr><td>0.02731</td><td>0.0</td><td>7.07</td><td>0.0</td><td>0.469</td><td>6.421</td><td>78.9</td><td>4.9671</td><td>2.0</td><td>242.0</td><td>17.8</td><td>396.9</td><td>9.14</td><td>21.6</td></tr>\n",
       "<tr><td>0.02729</td><td>0.0</td><td>7.07</td><td>0.0</td><td>0.469</td><td>7.185</td><td>61.1</td><td>4.9671</td><td>2.0</td><td>242.0</td><td>17.8</td><td>392.83</td><td>4.03</td><td>34.7</td></tr>\n",
       "<tr><td>0.03237</td><td>0.0</td><td>2.18</td><td>0.0</td><td>0.458</td><td>6.998</td><td>45.8</td><td>6.0622</td><td>3.0</td><td>222.0</td><td>18.7</td><td>394.63</td><td>2.94</td><td>33.4</td></tr>\n",
       "<tr><td>0.06905</td><td>0.0</td><td>2.18</td><td>0.0</td><td>0.458</td><td>7.147</td><td>54.2</td><td>6.0622</td><td>3.0</td><td>222.0</td><td>18.7</td><td>396.9</td><td>5.33</td><td>36.2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+---------+-----+----+-----+-----+----+--------+------+-----+-------+------+-----+-----+\n",
       "|crime_rate|land_rate|indus|chas|  nox| room| age|distance|radial|  tax|ptratio| black|lstat|price|\n",
       "+----------+---------+-----+----+-----+-----+----+--------+------+-----+-------+------+-----+-----+\n",
       "|   0.00632|     18.0| 2.31| 0.0|0.538|6.575|65.2|    4.09|   1.0|296.0|   15.3| 396.9| 4.98| 24.0|\n",
       "|   0.02731|      0.0| 7.07| 0.0|0.469|6.421|78.9|  4.9671|   2.0|242.0|   17.8| 396.9| 9.14| 21.6|\n",
       "|   0.02729|      0.0| 7.07| 0.0|0.469|7.185|61.1|  4.9671|   2.0|242.0|   17.8|392.83| 4.03| 34.7|\n",
       "|   0.03237|      0.0| 2.18| 0.0|0.458|6.998|45.8|  6.0622|   3.0|222.0|   18.7|394.63| 2.94| 33.4|\n",
       "|   0.06905|      0.0| 2.18| 0.0|0.458|7.147|54.2|  6.0622|   3.0|222.0|   18.7| 396.9| 5.33| 36.2|\n",
       "+----------+---------+-----+----+-----+-----+----+--------+------+-----+-------+------+-----+-----+"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = spark.read.csv(r'data\\boston.csv', header=True)\n",
    "boston = boston.select([F.col(c).cast('float') for c in boston.columns])\n",
    "boston.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = boston.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "\n",
    "boston = assembler.transform(boston)\n",
    "boston = boston.selectExpr('features', 'price AS label')\n",
    "boston_train, boston_test = boston.randomSplit([0.8, 0.2], seed=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(\n",
    "    impurity='variance',\n",
    "    maxDepth=8,\n",
    "    maxBins=16,\n",
    "    minInstancesPerNode=10,\n",
    "    minInfoGain=0.1,\n",
    "    minWeightFractionPerNode=0.2,\n",
    "    \n",
    "    lossType='logistic',\n",
    "    stepSize=0.1,\n",
    "    featureSubsetStrategy='all'\n",
    ")\n",
    "model = gbt.fit(iris_train.filter('y IN (0.0, 1.0)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_train = model.transform(iris_train.filter('y IN (0.0, 1.0)'))\n",
    "predictor_test = model.transform(iris_test.filter('y IN (0.0, 1.0)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC train = 1.0\n",
      "AUROC test = 1.0\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(metricName='areaUnderROC')\n",
    "\n",
    "auroc_train = evaluator.evaluate(predictor_train)\n",
    "auroc_test = evaluator.evaluate(predictor_test)\n",
    "print(f'AUROC train = {auroc_train}')\n",
    "print(f'AUROC test = {auroc_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC train = 1.0\n",
      "AUPRC test = 1.0\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "auprc_train = evaluator.setMetricName('areaUnderPR').evaluate(predictor_train)\n",
    "auprc_test = evaluator.evaluate(predictor_test, {evaluator.metricName: 'areaUnderPR'})\n",
    "print(f'AUPRC train = {auprc_train}')\n",
    "print(f'AUPRC test = {auprc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(\n",
    "    impurity='entropy',\n",
    "    maxDepth=8,\n",
    "    maxBins=16,\n",
    "    minInstancesPerNode=10,\n",
    "    minInfoGain=0.1,\n",
    "    minWeightFractionPerNode=0.2,\n",
    "    \n",
    "    numTrees=32,\n",
    "    featureSubsetStrategy='sqrt',\n",
    "    subsamplingRate=0.8\n",
    ")\n",
    "model = forest.fit(iris_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_train = model.transform(iris_train)\n",
    "predictor_test = model.transform(iris_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train = 0.9391304347826087\n",
      "Accuracy test = 0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "\n",
    "accuracy_train = evaluator.evaluate(predictor_train)\n",
    "accuracy_test = evaluator.evaluate(predictor_test)\n",
    "print(f'Accuracy train = {accuracy_train}')\n",
    "print(f'Accuracy test = {accuracy_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F4-score train = 0.9565018716598458\n",
      "F4-score test = 0.9713433491477772\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(metricName='weightedFMeasure', beta=4)\n",
    "\n",
    "f4_train = evaluator.evaluate(predictor_train)\n",
    "f4_test = evaluator.evaluate(predictor_test)\n",
    "print(f'F4-score train = {f4_train}')\n",
    "print(f'F4-score test = {f4_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(\n",
    "    impurity='variance',\n",
    "    maxDepth=8,\n",
    "    maxBins=16,\n",
    "    minInstancesPerNode=10,\n",
    "    minInfoGain=0.1,\n",
    "    minWeightFractionPerNode=0.2,\n",
    "    \n",
    "    lossType='squared',\n",
    "    stepSize=0.1,\n",
    "    featureSubsetStrategy='all'\n",
    ")\n",
    "model = gbt.fit(boston_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_train = model.transform(boston_train)\n",
    "predictor_test = model.transform(boston_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train = 24.404417240115315\n",
      "RMSE test = 23.713267870017162\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName='rmse')\n",
    "\n",
    "rmse_train = evaluator.evaluate(predictor_train)\n",
    "rmse_test = evaluator.evaluate(predictor_test)\n",
    "print(f'RMSE train = {rmse_train}')\n",
    "print(f'RMSE test = {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train = -6.02938448998077\n",
      "R2 test = -5.785781042168173\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName='r2')\n",
    "\n",
    "r2_train = evaluator.evaluate(predictor_train)\n",
    "r2_test = evaluator.evaluate(predictor_test)\n",
    "print(f'R2 train = {r2_train}')\n",
    "print(f'R2 test = {r2_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor, RandomForestRegressionModel\n",
    "from pyspark.ml.regression import GBTRegressor, GBTRegressionModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>crime_rate</th><th>land_rate</th><th>indus</th><th>chas</th><th>nox</th><th>room</th><th>age</th><th>distance</th><th>radial</th><th>tax</th><th>ptratio</th><th>black</th><th>lstat</th><th>price</th></tr>\n",
       "<tr><td>0.00632</td><td>18.0</td><td>2.31</td><td>0.0</td><td>0.538</td><td>6.575</td><td>65.2</td><td>4.09</td><td>1.0</td><td>296.0</td><td>15.3</td><td>396.9</td><td>4.98</td><td>24.0</td></tr>\n",
       "<tr><td>0.02731</td><td>0.0</td><td>7.07</td><td>0.0</td><td>0.469</td><td>6.421</td><td>78.9</td><td>4.9671</td><td>2.0</td><td>242.0</td><td>17.8</td><td>396.9</td><td>9.14</td><td>21.6</td></tr>\n",
       "<tr><td>0.02729</td><td>0.0</td><td>7.07</td><td>0.0</td><td>0.469</td><td>7.185</td><td>61.1</td><td>4.9671</td><td>2.0</td><td>242.0</td><td>17.8</td><td>392.83</td><td>4.03</td><td>34.7</td></tr>\n",
       "<tr><td>0.03237</td><td>0.0</td><td>2.18</td><td>0.0</td><td>0.458</td><td>6.998</td><td>45.8</td><td>6.0622</td><td>3.0</td><td>222.0</td><td>18.7</td><td>394.63</td><td>2.94</td><td>33.4</td></tr>\n",
       "<tr><td>0.06905</td><td>0.0</td><td>2.18</td><td>0.0</td><td>0.458</td><td>7.147</td><td>54.2</td><td>6.0622</td><td>3.0</td><td>222.0</td><td>18.7</td><td>396.9</td><td>5.33</td><td>36.2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+---------+-----+----+-----+-----+----+--------+------+-----+-------+------+-----+-----+\n",
       "|crime_rate|land_rate|indus|chas|  nox| room| age|distance|radial|  tax|ptratio| black|lstat|price|\n",
       "+----------+---------+-----+----+-----+-----+----+--------+------+-----+-------+------+-----+-----+\n",
       "|   0.00632|     18.0| 2.31| 0.0|0.538|6.575|65.2|    4.09|   1.0|296.0|   15.3| 396.9| 4.98| 24.0|\n",
       "|   0.02731|      0.0| 7.07| 0.0|0.469|6.421|78.9|  4.9671|   2.0|242.0|   17.8| 396.9| 9.14| 21.6|\n",
       "|   0.02729|      0.0| 7.07| 0.0|0.469|7.185|61.1|  4.9671|   2.0|242.0|   17.8|392.83| 4.03| 34.7|\n",
       "|   0.03237|      0.0| 2.18| 0.0|0.458|6.998|45.8|  6.0622|   3.0|222.0|   18.7|394.63| 2.94| 33.4|\n",
       "|   0.06905|      0.0| 2.18| 0.0|0.458|7.147|54.2|  6.0622|   3.0|222.0|   18.7| 396.9| 5.33| 36.2|\n",
       "+----------+---------+-----+----+-----+-----+----+--------+------+-----+-------+------+-----+-----+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = spark.read.csv(r'data\\boston.csv', header=True)\n",
    "boston = boston.select([F.col(c).cast('float') for c in boston.columns])\n",
    "boston.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = boston.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "\n",
    "boston = assembler.transform(boston)\n",
    "boston = boston.selectExpr('features', 'price AS label')\n",
    "boston_train, boston_test = boston.randomSplit([0.8, 0.2], seed=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor()\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(forest.numTrees, [32, 64])\\\n",
    "    .addGrid(forest.minInstancesPerNode, [5])\\\n",
    "    .addGrid(forest.featureSubsetStrategy, ['onethird', 'sqrt', 'log2'])\\\n",
    "    .addGrid(forest.maxDepth, [4, 8])\\\n",
    "    .addGrid(forest.subsamplingRate, [0.3, 0.5, 0.7])\\\n",
    "    .build()\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=forest, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)\n",
    "cvModel = cv.fit(boston_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.getNumTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.getMaxDepth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.getSubsamplingRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'onethird'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.getFeatureSubsetStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_train = cvModel.transform(boston_train)\n",
    "predictor_test = cvModel.transform(boston_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train = 3.056405635281502\n",
      "RMSE test = 3.3675065448742796\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName='rmse')\n",
    "\n",
    "rmse_train = evaluator.evaluate(predictor_train)\n",
    "rmse_test = evaluator.evaluate(predictor_test)\n",
    "print(f'RMSE train = {rmse_train}')\n",
    "print(f'RMSE test = {rmse_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor()\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(gbt.minInstancesPerNode, [10])\\\n",
    "    .addGrid(gbt.featureSubsetStrategy, ['onethird', 'sqrt', 'log2'])\\\n",
    "    .addGrid(gbt.stepSize, [0.05, 0.1, 0.15, 0.2, 0.25])\\\n",
    "    .build()\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=gbt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)\n",
    "cvModel = cv.fit(boston_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqrt'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.getFeatureSubsetStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.getStepSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_train = cvModel.transform(boston_train)\n",
    "predictor_test = cvModel.transform(boston_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train = 2.769704989113925\n",
      "RMSE test = 3.7868569935109253\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName='rmse')\n",
    "\n",
    "rmse_train = evaluator.evaluate(predictor_train)\n",
    "rmse_test = evaluator.evaluate(predictor_test)\n",
    "print(f'RMSE train = {rmse_train}')\n",
    "print(f'RMSE test = {rmse_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Micellaneous techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor, RandomForestRegressionModel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>crime_rate</th><th>land_rate</th><th>indus</th><th>chas</th><th>nox</th><th>room</th><th>age</th><th>distance</th><th>radial</th><th>tax</th><th>ptratio</th><th>black</th><th>lstat</th><th>price</th></tr>\n",
       "<tr><td>0.00632</td><td>18.0</td><td>2.31</td><td>0.0</td><td>0.538</td><td>6.575</td><td>65.2</td><td>4.09</td><td>1.0</td><td>296.0</td><td>15.3</td><td>396.9</td><td>4.98</td><td>24.0</td></tr>\n",
       "<tr><td>0.02731</td><td>0.0</td><td>7.07</td><td>0.0</td><td>0.469</td><td>6.421</td><td>78.9</td><td>4.9671</td><td>2.0</td><td>242.0</td><td>17.8</td><td>396.9</td><td>9.14</td><td>21.6</td></tr>\n",
       "<tr><td>0.02729</td><td>0.0</td><td>7.07</td><td>0.0</td><td>0.469</td><td>7.185</td><td>61.1</td><td>4.9671</td><td>2.0</td><td>242.0</td><td>17.8</td><td>392.83</td><td>4.03</td><td>34.7</td></tr>\n",
       "<tr><td>0.03237</td><td>0.0</td><td>2.18</td><td>0.0</td><td>0.458</td><td>6.998</td><td>45.8</td><td>6.0622</td><td>3.0</td><td>222.0</td><td>18.7</td><td>394.63</td><td>2.94</td><td>33.4</td></tr>\n",
       "<tr><td>0.06905</td><td>0.0</td><td>2.18</td><td>0.0</td><td>0.458</td><td>7.147</td><td>54.2</td><td>6.0622</td><td>3.0</td><td>222.0</td><td>18.7</td><td>396.9</td><td>5.33</td><td>36.2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+---------+-----+----+-----+-----+----+--------+------+-----+-------+------+-----+-----+\n",
       "|crime_rate|land_rate|indus|chas|  nox| room| age|distance|radial|  tax|ptratio| black|lstat|price|\n",
       "+----------+---------+-----+----+-----+-----+----+--------+------+-----+-------+------+-----+-----+\n",
       "|   0.00632|     18.0| 2.31| 0.0|0.538|6.575|65.2|    4.09|   1.0|296.0|   15.3| 396.9| 4.98| 24.0|\n",
       "|   0.02731|      0.0| 7.07| 0.0|0.469|6.421|78.9|  4.9671|   2.0|242.0|   17.8| 396.9| 9.14| 21.6|\n",
       "|   0.02729|      0.0| 7.07| 0.0|0.469|7.185|61.1|  4.9671|   2.0|242.0|   17.8|392.83| 4.03| 34.7|\n",
       "|   0.03237|      0.0| 2.18| 0.0|0.458|6.998|45.8|  6.0622|   3.0|222.0|   18.7|394.63| 2.94| 33.4|\n",
       "|   0.06905|      0.0| 2.18| 0.0|0.458|7.147|54.2|  6.0622|   3.0|222.0|   18.7| 396.9| 5.33| 36.2|\n",
       "+----------+---------+-----+----+-----+-----+----+--------+------+-----+-------+------+-----+-----+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = spark.read.csv(r'data\\boston.csv', header=True)\n",
    "boston = boston.select([F.col(c).cast('float') for c in boston.columns])\n",
    "boston.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = boston.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "\n",
    "boston = assembler.transform(boston)\n",
    "boston = boston.selectExpr('features', 'price AS label')\n",
    "boston_train, boston_test = boston.randomSplit([0.8, 0.2], seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(\n",
    "    impurity='variance',\n",
    "    maxDepth=8,\n",
    "    maxBins=32,\n",
    "    minInstancesPerNode=5,\n",
    "    minInfoGain=0.0,\n",
    "    minWeightFractionPerNode=0.0,\n",
    "    \n",
    "    numTrees=64,\n",
    "    featureSubsetStrategy='onethird',\n",
    "    subsamplingRate=0.7\n",
    ")\n",
    "model = forest.fit(boston_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rf_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressionModel: uid=RandomForestRegressor_8f29ad6d5173, numTrees=64, numFeatures=13"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestRegressionModel().load('rf_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features', 'label']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'score': model.featureImportances.values\n",
    "})\n",
    "\n",
    "_ = df\\\n",
    "    .sort_values('score')\\\n",
    "    .plot(x='feature', y='score', kind='barh', sort_columns='score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
