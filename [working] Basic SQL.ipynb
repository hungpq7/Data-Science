{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94179a41-63d0-4378-8433-6ef89d054a58",
   "metadata": {},
   "source": [
    "JupyterLab allows writing SQL query directly in-cell, thanks to the `%sparksql` magic command (use two percent signs `%%sparksql` to span code in multiple lines). An amazing feature is that PySpark can also interacts with this enviroment. This means all local files can be read as Hive tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a302ccd3-92cd-476f-87f5-b69b8e120e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "spark.conf.set('spark.sql.repl.eagerEval.truncate', 80)\n",
    "spark.conf.set('spark.sql.repl.eagerEval.maxNumRows', 20)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f752b6be-ab7c-448e-a961-aca186aea0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext sparksql_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f63df25-8896-4cd6-9dfb-8b60c3c2a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config SparkSql.limit=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae05da-5a21-479f-a657-55cb8f1a44cd",
   "metadata": {},
   "source": [
    "# 1. Managing tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb8cfa0-751a-4550-bd78-7c674d539e24",
   "metadata": {},
   "source": [
    "## 1.1. Creating tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a72c26f-bfe0-4fc5-ad4b-feaa2509868c",
   "metadata": {},
   "source": [
    "#### Manually creating tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "061d3c27-ec86-4cb5-87eb-122fdcdfc85b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS tbl_product\n",
    "STORED AS PARQUET\n",
    "LOCATION 'spark_db/tbl_product'\n",
    "TBLPROPERTIES ('parquet.compression'='snappy')\n",
    "\n",
    "SELECT *\n",
    "FROM VALUES\n",
    "    ('Laptop', 1000, 15),\n",
    "    ('Mouse', 20, 100),\n",
    "    ('Headphone', 50, 50),\n",
    "    ('USB', NULL, 100)\n",
    "AS (product, price, stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81b245-61f5-4bc3-925b-d560bf04c487",
   "metadata": {},
   "source": [
    "#### Metadata\n",
    "\n",
    "|Statement|Usage|\n",
    "|:--|:--|\n",
    "|`DESC <table_name>`|Show columns and comments of a table|\n",
    "|`DESC FORMATTED <table_name>`|Show detailed information of a table|\n",
    "|`SHOW CREATE TABLE <table_name>`|Get the script that created the table|\n",
    "|`DROP TABLE IF EXISTS <table_name>`|Drop a table|\n",
    "|`SHOW DATABASES`|Show all available databases|\n",
    "|`DESC DATABASE EXTENDED <database_name>`|Show information about a database|\n",
    "|`USE <database_name>`|Enter a specific database|\n",
    "|`SHOW TABLES`|Show all available tables and view|\n",
    "|`SHOW TABLES LIKE <pattern>`| Show all tables having a specific pattern in their name|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0b1e2d-f586-46a5-a615-52d65aee7136",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">col_name</td><td style=\"font-weight: bold\">data_type</td><td style=\"font-weight: bold\">comment</td></tr><tr><td>product</td><td>string</td><td>null</td></tr><tr><td>price</td><td>int</td><td>null</td></tr><tr><td>stock</td><td>int</td><td>null</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "DESC tbl_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11161110-d3a2-424f-8cee-efc7cd44e6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">database</td><td style=\"font-weight: bold\">tableName</td><td style=\"font-weight: bold\">isTemporary</td></tr><tr><td>default</td><td>tbl_product</td><td>False</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "SHOW TABLES LIKE '*product*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff92ecfd-9bf6-44d3-a154-07d1c729aeeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "ALTER TABLE tbl_product SET TBLPROPERTIES('external'='false', 'auto.purge'='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f691b99-6ea0-4822-8a84-01d91821ee40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "DROP TABLE IF EXISTS tbl_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f4aa2-5c85-4cdf-8468-d9c91f418e1a",
   "metadata": {},
   "source": [
    "#### Partitioning\n",
    "A unique feature of SparkSQL is organizing tables in partitions, which helps achieve more parallelism. A categorical column or two may be used as partition columns. Data can be inserted to a partition using `INSERT INTO TABLE` or `INSERT OVERWRITE TABLE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32cae013-2b06-4e40-bff1-800eaaf949ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS tbl_product (\n",
    "    product STRING COMMENT 'name of product',\n",
    "    price INT COMMENT 'price of product',\n",
    "    stock INT COMMENT 'number of products left'\n",
    ")\n",
    "PARTITIONED BY (day STRING COMMENT 'day', hour STRING COMMENT 'hour')\n",
    "STORED AS PARQUET\n",
    "LOCATION 'spark_db/tbl_product'\n",
    "TBLPROPERTIES ('parquet.compression'='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c6ebc0-f4ec-4095-995e-12ad5fd0319b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "INSERT OVERWRITE TABLE tbl_product\n",
    "PARTITION (day=20210725, hour=14)\n",
    "VALUES\n",
    "    ('Laptop', 1000, 25),\n",
    "    ('Mouse', 30, 100),\n",
    "    ('Headphone', 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021bc6be-0b32-4bfb-a0b0-489d110ef39a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "INSERT INTO TABLE tbl_product\n",
    "PARTITION (day=20210725, hour=21)\n",
    "VALUES\n",
    "    ('Laptop', 1000, 20),\n",
    "    ('Mouse', 20, 97),\n",
    "    ('Headphone', 65, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953ca4ce-12ab-4571-9df7-418c1ea866b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">partition</td></tr><tr><td>day=20210725/hour=14</td></tr><tr><td>day=20210725/hour=21</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "SHOW PARTITIONS tbl_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc503ab0-f36f-4aef-a51a-9474da87c0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "ALTER TABLE tbl_product DROP IF EXISTS PARTITION (day=20210725)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ec8ac-f34f-426d-80ec-7c16a71de8fb",
   "metadata": {},
   "source": [
    "## 1.2. Importing local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33e84ce-d0c5-4736-bceb-73b22a4d99ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/youtube_trending.csv', header=True, inferSchema=True)\n",
    "\n",
    "df\\\n",
    "    .write.format('parquet')\\\n",
    "    .option('path', 'spark_db/tbl_youtube')\\\n",
    "    .option('compression', 'snappy')\\\n",
    "    .mode('overwrite').saveAsTable('tbl_youtube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edb308b9-6b6a-40e2-ab63-8cd6dbbfd91a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">video_id</td><td style=\"font-weight: bold\">trending_date</td><td style=\"font-weight: bold\">channel_title</td><td style=\"font-weight: bold\">category_id</td><td style=\"font-weight: bold\">publish_time</td><td style=\"font-weight: bold\">views</td><td style=\"font-weight: bold\">likes</td><td style=\"font-weight: bold\">dislikes</td><td style=\"font-weight: bold\">comment_count</td><td style=\"font-weight: bold\">comments_disabled</td><td style=\"font-weight: bold\">ratings_disabled</td></tr><tr><td>2kyS6SvSYSE</td><td>2017-11-14</td><td>CaseyNeistat</td><td>22</td><td>2017-11-14 00:13:01</td><td>748374</td><td>57527</td><td>2966</td><td>15954</td><td>False</td><td>False</td></tr><tr><td>1ZAPwfrtAFY</td><td>2017-11-14</td><td>LastWeekTonight</td><td>24</td><td>2017-11-13 14:30:00</td><td>2418783</td><td>97185</td><td>6146</td><td>12703</td><td>False</td><td>False</td></tr><tr><td>5qpjK5DgCt4</td><td>2017-11-14</td><td>Rudy Mancuso</td><td>23</td><td>2017-11-13 02:05:24</td><td>3191434</td><td>146033</td><td>5339</td><td>8181</td><td>False</td><td>False</td></tr><tr><td>puqaWrEC7tY</td><td>2017-11-14</td><td>Good Mythical Morning</td><td>24</td><td>2017-11-13 18:00:04</td><td>343168</td><td>10172</td><td>666</td><td>2146</td><td>False</td><td>False</td></tr><tr><td>d380meD0W0M</td><td>2017-11-14</td><td>nigahiga</td><td>24</td><td>2017-11-13 01:01:41</td><td>2095731</td><td>132235</td><td>1989</td><td>17518</td><td>False</td><td>False</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "SELECT * FROM tbl_youtube LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3cc2c5-418a-4380-94f0-b628302a5d13",
   "metadata": {},
   "source": [
    "## 1.3. Hive data types\n",
    "Data types and coverting between them, especially datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75cb7e-aaad-4bd2-bfb4-f3263e1a4651",
   "metadata": {},
   "source": [
    "## 1.4. Aliases\n",
    "- Table aliases\n",
    "- Column aliases\n",
    "- Use `` for specifying names: \n",
    "\n",
    "```sql\n",
    "`schema`.`database`.`table`.`column`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32967bff-1947-4d0c-a4f7-cea71dc1827f",
   "metadata": {},
   "source": [
    "# 2. Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585951af-85f7-496d-855a-1a2751fdba97",
   "metadata": {},
   "source": [
    "## 2.1. Filtering\n",
    "```sql\n",
    "RLIKE | LIKE | IN | IS NULL\n",
    "```\n",
    "note: how to use NOT, AND, OR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de469f7f-ef13-4411-bd21-8d966671d0b1",
   "metadata": {},
   "source": [
    "## 2.2. Aggregating\n",
    "\n",
    "```sql\n",
    "GROUP BY: COUNT(*), COUNT(DISTINCT), COUNT(CASE WHEN), SUM, SUM(DISTINCT), AVG, AVG(DISTINCT), MIN, MAX, VAR_POP, STDDEV_POP, PERCENTILE\n",
    "```\n",
    "\n",
    "*Reference: [Apache Hive - Aggregate functions](https://cwiki.apache.org/confluence/display/hive/languagemanual+udf#LanguageManualUDF-Built-inAggregateFunctions(UDAF))*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f1bac-fd33-468d-89f1-ca685100dff5",
   "metadata": {},
   "source": [
    "## 2.3. Window functions\n",
    "\n",
    "- Windows functions: ROW_NUMBER, RANK, DENSE_RANK, NTILE,... (same as in pyspark)\n",
    "- Special uses of SUM, COUNT (with or without PARTITION BY)\n",
    "- ROW|RANGE BETWEEN, UNBOUNDED, PRECEDING, CURRENT_ROW,...\n",
    "\n",
    "*Reference: [Apache Hive - Window functions](https://cwiki.apache.org/confluence/display/hive/languagemanual+windowingandanalytics)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daa92ef-9298-472a-9382-cc37b691a353",
   "metadata": {},
   "source": [
    "## 2.3. Gathering data\n",
    "- `JOIN`: cross, left, right, inner, outer\n",
    "- `UNION`: all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee03f00d-c30e-4d8b-a652-e761a74a3481",
   "metadata": {},
   "source": [
    "## 2.4. Order of execution\n",
    "```sql\n",
    "FROM -> JOIN [ON] -> WHERE -> GROUP BY -> HAVING -> SELECT -> ORDER BY -> LIMIT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430361cc-eaaf-4deb-b33b-caab1723b25e",
   "metadata": {},
   "source": [
    "## 2.5. Functions\n",
    "```sql\n",
    "PI, RAND, LOG, SQRT, POW/POWER, CONCAT, CONCAT_WS, NVL, NVL2, REGEXP_REPLACE, REGEXP_EXTRACT, SPLIT, GREATEST, LEAST, LOWER/UPPER, LENGTH, NULLIF, LPAD/RPAD, LTRIM/RTRIM/TRIM, SUBSTR/SUBSTRING, CASE WHEN\n",
    "```\n",
    "\n",
    "*Reference: [Apache Hive - Built-in functions](https://cwiki.apache.org/confluence/display/hive/languagemanual+udf#LanguageManualUDF-Built-inFunctions)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f4ee4-59ee-4667-b2fc-64c4fec46791",
   "metadata": {},
   "source": [
    "# 3. Data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1282a5b5-f70e-42db-88c0-04bbfa56ee19",
   "metadata": {},
   "source": [
    "## 3.1. Array type\n",
    "- Definition: same as Numpy's array\n",
    "- Schema: `ARRAY<STRING>`\n",
    "- Inserting: `ARRAY('hung', 'linh',...)`\n",
    "- Accessing: `A[1]`, start with 0\n",
    "- Techniques:\n",
    "    - Unpacking: `LATERAL VIEW, EXPLODE, POSEXPLODE, INLINE,...`\n",
    "    - Higher order functions: `TRANSFORM, FILTER, EXISTS, AGGREGATE` ([read more](https://databricks.com/blog/2017/05/24/working-with-nested-data-using-higher-order-functions-in-sql-on-databricks.html))\n",
    "    - Basic functions: `SIZE, ARRAY_CONTAINS, SORT_ARRAY, CONCAT_WS, SEQUENCE,...` (same as in pyspark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c9fc8-0dc5-4f5d-9400-b709f2cf41b0",
   "metadata": {},
   "source": [
    "## 3.2. Struct type\n",
    "- Definition: two or more arrays zipped together\n",
    "- Schema: `ARRAY<STRUCT<id:INT, name:STRING, interest:STRING>>`\n",
    "- Inserting: `ARRAY(STRUCT(0, 'hung', 'buom'), STRUCT(1, 'linh', 'chim'))`\n",
    "- Accessing: `S.id, S.name, S.interest`\n",
    "- Techniques: `ARRAYS_ZIP`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc3481-0f10-4a73-9654-83d2e88babcf",
   "metadata": {},
   "source": [
    "## 3.3. Map type\n",
    "- Definition: same as Python's dict\n",
    "- Schema: `MAP<STRING, STRING>`\n",
    "- Inserting: `MAP('0', 'hung', '1', 'linh')`\n",
    "- Accessing: `M['0']`\n",
    "- Techniques:\n",
    "    - `LATERAL VIEW, EXPLODE, POSEEXPLODE, INLINE,...`\n",
    "    - `MAP_KEYS, MAP_VALUES, STR_TO_MAP`\n",
    "    - `GET_JSON_OBJECT`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
