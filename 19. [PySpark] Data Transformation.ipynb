{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Miscellaneous techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Mapping\n",
    "Mapping in PySpark requires using the `udf()` function, which allows a Python function to work on PySpark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>manufacturer</th><th>model</th><th>type</th><th>min_price</th><th>price</th><th>max_price</th><th>mpg_city</th><th>mpg_highway</th><th>airbags</th><th>drive_train</th><th>cylinders</th><th>engine_size</th><th>horsepower</th><th>rpm</th><th>rev_per_mile</th><th>man_trans_avail</th><th>fuel_tank_capacity</th><th>passengers</th><th>length</th><th>wheelbase</th><th>width</th><th>turn_circle</th><th>rear_seat_room</th><th>luggage_room</th><th>weight</th><th>origin</th><th>make</th></tr>\n",
       "<tr><td>Chevrolet</td><td>Cavalier</td><td>Compact</td><td>8.5</td><td>13.4</td><td>18.3</td><td>25</td><td>36</td><td>None</td><td>Front</td><td>4.0</td><td>2.2</td><td>110</td><td>5200</td><td>2380</td><td>Yes</td><td>15.2</td><td>5</td><td>182</td><td>101</td><td>66</td><td>38</td><td>25.0</td><td>13.0</td><td>2490</td><td>USA</td><td>Chevrolet Cavalier</td></tr>\n",
       "<tr><td>Chevrolet</td><td>Corsica</td><td>Compact</td><td>11.4</td><td>11.4</td><td>11.4</td><td>25</td><td>34</td><td>Driver only</td><td>Front</td><td>4.0</td><td>2.2</td><td>110</td><td>5200</td><td>2665</td><td>Yes</td><td>15.6</td><td>5</td><td>184</td><td>103</td><td>68</td><td>39</td><td>26.0</td><td>14.0</td><td>2785</td><td>USA</td><td>Chevrolet Corsica</td></tr>\n",
       "<tr><td>Chevrolet</td><td>Camaro</td><td>Sporty</td><td>13.4</td><td>15.1</td><td>16.8</td><td>19</td><td>28</td><td>Driver &amp; Passenger</td><td>Rear</td><td>6.0</td><td>3.4</td><td>160</td><td>4600</td><td>1805</td><td>Yes</td><td>15.5</td><td>4</td><td>193</td><td>101</td><td>74</td><td>43</td><td>25.0</td><td>13.0</td><td>3240</td><td>USA</td><td>Chevrolet Camaro</td></tr>\n",
       "<tr><td>Chevrolet</td><td>Lumina</td><td>Midsize</td><td>13.4</td><td>15.9</td><td>18.4</td><td>21</td><td>29</td><td>None</td><td>Front</td><td>4.0</td><td>2.2</td><td>110</td><td>5200</td><td>2595</td><td>No</td><td>16.5</td><td>6</td><td>198</td><td>108</td><td>71</td><td>40</td><td>28.5</td><td>16.0</td><td>3195</td><td>USA</td><td>Chevrolet Lumina</td></tr>\n",
       "<tr><td>Chevrolet</td><td>Lumina_APV</td><td>Van</td><td>14.7</td><td>16.3</td><td>18.0</td><td>18</td><td>23</td><td>None</td><td>Front</td><td>6.0</td><td>3.8</td><td>170</td><td>4800</td><td>1690</td><td>No</td><td>20.0</td><td>7</td><td>178</td><td>110</td><td>74</td><td>44</td><td>30.5</td><td>null</td><td>3715</td><td>USA</td><td>Chevrolet Lumina_APV</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+----------+-------+---------+-----+---------+--------+-----------+------------------+-----------+---------+-----------+----------+----+------------+---------------+------------------+----------+------+---------+-----+-----------+--------------+------------+------+------+--------------------+\n",
       "|manufacturer|     model|   type|min_price|price|max_price|mpg_city|mpg_highway|           airbags|drive_train|cylinders|engine_size|horsepower| rpm|rev_per_mile|man_trans_avail|fuel_tank_capacity|passengers|length|wheelbase|width|turn_circle|rear_seat_room|luggage_room|weight|origin|                make|\n",
       "+------------+----------+-------+---------+-----+---------+--------+-----------+------------------+-----------+---------+-----------+----------+----+------------+---------------+------------------+----------+------+---------+-----+-----------+--------------+------------+------+------+--------------------+\n",
       "|   Chevrolet|  Cavalier|Compact|      8.5| 13.4|     18.3|      25|         36|              None|      Front|      4.0|        2.2|       110|5200|        2380|            Yes|              15.2|         5|   182|      101|   66|         38|          25.0|        13.0|  2490|   USA|  Chevrolet Cavalier|\n",
       "|   Chevrolet|   Corsica|Compact|     11.4| 11.4|     11.4|      25|         34|       Driver only|      Front|      4.0|        2.2|       110|5200|        2665|            Yes|              15.6|         5|   184|      103|   68|         39|          26.0|        14.0|  2785|   USA|   Chevrolet Corsica|\n",
       "|   Chevrolet|    Camaro| Sporty|     13.4| 15.1|     16.8|      19|         28|Driver & Passenger|       Rear|      6.0|        3.4|       160|4600|        1805|            Yes|              15.5|         4|   193|      101|   74|         43|          25.0|        13.0|  3240|   USA|    Chevrolet Camaro|\n",
       "|   Chevrolet|    Lumina|Midsize|     13.4| 15.9|     18.4|      21|         29|              None|      Front|      4.0|        2.2|       110|5200|        2595|             No|              16.5|         6|   198|      108|   71|         40|          28.5|        16.0|  3195|   USA|    Chevrolet Lumina|\n",
       "|   Chevrolet|Lumina_APV|    Van|     14.7| 16.3|     18.0|      18|         23|              None|      Front|      6.0|        3.8|       170|4800|        1690|             No|              20.0|         7|   178|      110|   74|         44|          30.5|        null|  3715|   USA|Chevrolet Lumina_APV|\n",
       "+------------+----------+-------+---------+-----+---------+--------+-----------+------------------+-----------+---------+-----------+----------+----+------------+---------------+------------------+----------+------+---------+-----+-----------+--------------+------------+------+------+--------------------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = pd.read_excel(r'data\\cars.xlsx')\n",
    "cars = spark.createDataFrame(cars.astype(str)).replace('nan', None)\n",
    "cars = cars.withColumn('price', F.col('price').cast('float'))\n",
    "cars.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.600000381469727, 15.899999618530273, 18.799999237060547]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.approxQuantile('price', [0.25, 0.5, 0.75], relativeError=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp_getPriceLevel(price):\n",
    "    if price < 11.6:\n",
    "        return 'very low'\n",
    "    elif price < 15.9:\n",
    "        return 'low'\n",
    "    elif price < 18.8:\n",
    "        return 'high'\n",
    "    else:\n",
    "        return 'very high'\n",
    "\n",
    "getPriceLevel = F.udf(lambda price: tmp_getPriceLevel(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>price</th><th>price_level</th></tr>\n",
       "<tr><td>13.4</td><td>low</td></tr>\n",
       "<tr><td>11.4</td><td>very low</td></tr>\n",
       "<tr><td>15.1</td><td>low</td></tr>\n",
       "<tr><td>15.9</td><td>low</td></tr>\n",
       "<tr><td>16.3</td><td>high</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+-----------+\n",
       "|price|price_level|\n",
       "+-----+-----------+\n",
       "| 13.4|        low|\n",
       "| 11.4|   very low|\n",
       "| 15.1|        low|\n",
       "| 15.9|        low|\n",
       "| 16.3|       high|\n",
       "+-----+-----------+"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.select('price', getPriceLevel('price').alias('price_level')).limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Window functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T15:29:19.488196Z",
     "iopub.status.busy": "2021-07-02T15:29:19.487195Z",
     "iopub.status.idle": "2021-07-02T15:29:30.450876Z",
     "shell.execute_reply": "2021-07-02T15:29:30.449878Z",
     "shell.execute_reply.started": "2021-07-02T15:29:19.487195Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T15:31:19.233998Z",
     "iopub.status.busy": "2021-07-02T15:31:19.232999Z",
     "iopub.status.idle": "2021-07-02T15:31:30.976484Z",
     "shell.execute_reply": "2021-07-02T15:31:30.976484Z",
     "shell.execute_reply.started": "2021-07-02T15:31:19.233998Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>employee</th><th>department</th><th>salary</th></tr>\n",
       "<tr><td>James</td><td>Sales</td><td>3000</td></tr>\n",
       "<tr><td>Harry</td><td>Sales</td><td>3500</td></tr>\n",
       "<tr><td>Ash</td><td>Sales</td><td>3000</td></tr>\n",
       "<tr><td>Michael</td><td>Sales</td><td>4600</td></tr>\n",
       "<tr><td>Robert</td><td>Sales</td><td>4100</td></tr>\n",
       "<tr><td>Maria</td><td>Finance</td><td>3000</td></tr>\n",
       "<tr><td>Wayne</td><td>Sales</td><td>3000</td></tr>\n",
       "<tr><td>Scott</td><td>Finance</td><td>3300</td></tr>\n",
       "<tr><td>Jen</td><td>Finance</td><td>3900</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>3000</td></tr>\n",
       "<tr><td>Kumar</td><td>Marketing</td><td>2000</td></tr>\n",
       "<tr><td>Saif</td><td>Sales</td><td>4100</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+----------+------+\n",
       "|employee|department|salary|\n",
       "+--------+----------+------+\n",
       "|   James|     Sales|  3000|\n",
       "|   Harry|     Sales|  3500|\n",
       "|     Ash|     Sales|  3000|\n",
       "| Michael|     Sales|  4600|\n",
       "|  Robert|     Sales|  4100|\n",
       "|   Maria|   Finance|  3000|\n",
       "|   Wayne|     Sales|  3000|\n",
       "|   Scott|   Finance|  3300|\n",
       "|     Jen|   Finance|  3900|\n",
       "|    Jeff| Marketing|  3000|\n",
       "|   Kumar| Marketing|  2000|\n",
       "|    Saif|     Sales|  4100|\n",
       "+--------+----------+------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    ('James', 'Sales', 3000),\n",
    "    ('Harry', 'Sales', 3500),\n",
    "    ('Ash', 'Sales', 3000),\n",
    "    ('Michael', 'Sales', 4600),\n",
    "    ('Robert', 'Sales', 4100),\n",
    "    ('Maria', 'Finance', 3000),\n",
    "    ('Wayne', 'Sales', 3000),\n",
    "    ('Scott', 'Finance', 3300),\n",
    "    ('Jen', 'Finance', 3900),\n",
    "    ('Jeff', 'Marketing', 3000),\n",
    "    ('Kumar', 'Marketing', 2000),\n",
    "    ('Saif', 'Sales', 4100))\n",
    " \n",
    "columns= ['employee', 'department', 'salary']\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to activate window functions, we firstly initialize the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T15:29:56.654268Z",
     "iopub.status.busy": "2021-07-02T15:29:56.654268Z",
     "iopub.status.idle": "2021-07-02T15:29:56.784984Z",
     "shell.execute_reply": "2021-07-02T15:29:56.783997Z",
     "shell.execute_reply.started": "2021-07-02T15:29:56.654268Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "window = Window.partitionBy('department').orderBy('salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T15:31:30.980083Z",
     "iopub.status.busy": "2021-07-02T15:31:30.976484Z",
     "iopub.status.idle": "2021-07-02T15:31:46.097841Z",
     "shell.execute_reply": "2021-07-02T15:31:46.096280Z",
     "shell.execute_reply.started": "2021-07-02T15:31:30.980083Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>employee</th><th>department</th><th>salary</th><th>row_number</th><th>rank</th><th>dense_rank</th><th>percent_rank</th><th>cume_dist</th><th>ntile_3</th></tr>\n",
       "<tr><td>James</td><td>Sales</td><td>3000</td><td>1</td><td>1</td><td>1</td><td>0.0</td><td>0.43</td><td>1</td></tr>\n",
       "<tr><td>Ash</td><td>Sales</td><td>3000</td><td>2</td><td>1</td><td>1</td><td>0.0</td><td>0.43</td><td>1</td></tr>\n",
       "<tr><td>Wayne</td><td>Sales</td><td>3000</td><td>3</td><td>1</td><td>1</td><td>0.0</td><td>0.43</td><td>1</td></tr>\n",
       "<tr><td>Harry</td><td>Sales</td><td>3500</td><td>4</td><td>4</td><td>2</td><td>0.5</td><td>0.57</td><td>2</td></tr>\n",
       "<tr><td>Robert</td><td>Sales</td><td>4100</td><td>5</td><td>5</td><td>3</td><td>0.67</td><td>0.86</td><td>2</td></tr>\n",
       "<tr><td>Saif</td><td>Sales</td><td>4100</td><td>6</td><td>5</td><td>3</td><td>0.67</td><td>0.86</td><td>3</td></tr>\n",
       "<tr><td>Michael</td><td>Sales</td><td>4600</td><td>7</td><td>7</td><td>4</td><td>1.0</td><td>1.0</td><td>3</td></tr>\n",
       "<tr><td>Maria</td><td>Finance</td><td>3000</td><td>1</td><td>1</td><td>1</td><td>0.0</td><td>0.33</td><td>1</td></tr>\n",
       "<tr><td>Scott</td><td>Finance</td><td>3300</td><td>2</td><td>2</td><td>2</td><td>0.5</td><td>0.67</td><td>2</td></tr>\n",
       "<tr><td>Jen</td><td>Finance</td><td>3900</td><td>3</td><td>3</td><td>3</td><td>1.0</td><td>1.0</td><td>3</td></tr>\n",
       "<tr><td>Kumar</td><td>Marketing</td><td>2000</td><td>1</td><td>1</td><td>1</td><td>0.0</td><td>0.5</td><td>1</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>3000</td><td>2</td><td>2</td><td>2</td><td>1.0</td><td>1.0</td><td>2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+----------+------+----------+----+----------+------------+---------+-------+\n",
       "|employee|department|salary|row_number|rank|dense_rank|percent_rank|cume_dist|ntile_3|\n",
       "+--------+----------+------+----------+----+----------+------------+---------+-------+\n",
       "|   James|     Sales|  3000|         1|   1|         1|         0.0|     0.43|      1|\n",
       "|     Ash|     Sales|  3000|         2|   1|         1|         0.0|     0.43|      1|\n",
       "|   Wayne|     Sales|  3000|         3|   1|         1|         0.0|     0.43|      1|\n",
       "|   Harry|     Sales|  3500|         4|   4|         2|         0.5|     0.57|      2|\n",
       "|  Robert|     Sales|  4100|         5|   5|         3|        0.67|     0.86|      2|\n",
       "|    Saif|     Sales|  4100|         6|   5|         3|        0.67|     0.86|      3|\n",
       "| Michael|     Sales|  4600|         7|   7|         4|         1.0|      1.0|      3|\n",
       "|   Maria|   Finance|  3000|         1|   1|         1|         0.0|     0.33|      1|\n",
       "|   Scott|   Finance|  3300|         2|   2|         2|         0.5|     0.67|      2|\n",
       "|     Jen|   Finance|  3900|         3|   3|         3|         1.0|      1.0|      3|\n",
       "|   Kumar| Marketing|  2000|         1|   1|         1|         0.0|      0.5|      1|\n",
       "|    Jeff| Marketing|  3000|         2|   2|         2|         1.0|      1.0|      2|\n",
       "+--------+----------+------+----------+----+----------+------------+---------+-------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\\\n",
    "    .withColumn('row_number', F.row_number().over(window))\\\n",
    "    .withColumn('rank', F.rank().over(window))\\\n",
    "    .withColumn('dense_rank', F.dense_rank().over(window))\\\n",
    "    .withColumn('percent_rank', F.round(F.percent_rank().over(window), 2))\\\n",
    "    .withColumn('cume_dist', F.round(F.cume_dist().over(window), 2))\\\n",
    "    .withColumn('ntile_3', F.ntile(3).over(window))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>employee</th><th>department</th><th>salary</th><th>lag_1</th><th>lead_2</th></tr>\n",
       "<tr><td>James</td><td>Sales</td><td>3000</td><td>null</td><td>3000</td></tr>\n",
       "<tr><td>Ash</td><td>Sales</td><td>3000</td><td>3000</td><td>3500</td></tr>\n",
       "<tr><td>Wayne</td><td>Sales</td><td>3000</td><td>3000</td><td>4100</td></tr>\n",
       "<tr><td>Harry</td><td>Sales</td><td>3500</td><td>3000</td><td>4100</td></tr>\n",
       "<tr><td>Robert</td><td>Sales</td><td>4100</td><td>3500</td><td>4600</td></tr>\n",
       "<tr><td>Saif</td><td>Sales</td><td>4100</td><td>4100</td><td>null</td></tr>\n",
       "<tr><td>Michael</td><td>Sales</td><td>4600</td><td>4100</td><td>null</td></tr>\n",
       "<tr><td>Maria</td><td>Finance</td><td>3000</td><td>null</td><td>3900</td></tr>\n",
       "<tr><td>Scott</td><td>Finance</td><td>3300</td><td>3000</td><td>null</td></tr>\n",
       "<tr><td>Jen</td><td>Finance</td><td>3900</td><td>3300</td><td>null</td></tr>\n",
       "<tr><td>Kumar</td><td>Marketing</td><td>2000</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>3000</td><td>2000</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+----------+------+-----+------+\n",
       "|employee|department|salary|lag_1|lead_2|\n",
       "+--------+----------+------+-----+------+\n",
       "|   James|     Sales|  3000| null|  3000|\n",
       "|     Ash|     Sales|  3000| 3000|  3500|\n",
       "|   Wayne|     Sales|  3000| 3000|  4100|\n",
       "|   Harry|     Sales|  3500| 3000|  4100|\n",
       "|  Robert|     Sales|  4100| 3500|  4600|\n",
       "|    Saif|     Sales|  4100| 4100|  null|\n",
       "| Michael|     Sales|  4600| 4100|  null|\n",
       "|   Maria|   Finance|  3000| null|  3900|\n",
       "|   Scott|   Finance|  3300| 3000|  null|\n",
       "|     Jen|   Finance|  3900| 3300|  null|\n",
       "|   Kumar| Marketing|  2000| null|  null|\n",
       "|    Jeff| Marketing|  3000| 2000|  null|\n",
       "+--------+----------+------+-----+------+"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\\\n",
    "    .withColumn('lag_1', F.lag('salary', 1).over(window))\\\n",
    "    .withColumn('lead_2', F.lead('salary', 2).over(window))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>employee</th><th>department</th><th>salary</th><th>cumsum</th></tr>\n",
       "<tr><td>James</td><td>Sales</td><td>3000</td><td>9000</td></tr>\n",
       "<tr><td>Ash</td><td>Sales</td><td>3000</td><td>9000</td></tr>\n",
       "<tr><td>Wayne</td><td>Sales</td><td>3000</td><td>9000</td></tr>\n",
       "<tr><td>Harry</td><td>Sales</td><td>3500</td><td>12500</td></tr>\n",
       "<tr><td>Robert</td><td>Sales</td><td>4100</td><td>20700</td></tr>\n",
       "<tr><td>Saif</td><td>Sales</td><td>4100</td><td>20700</td></tr>\n",
       "<tr><td>Michael</td><td>Sales</td><td>4600</td><td>25300</td></tr>\n",
       "<tr><td>Maria</td><td>Finance</td><td>3000</td><td>3000</td></tr>\n",
       "<tr><td>Scott</td><td>Finance</td><td>3300</td><td>6300</td></tr>\n",
       "<tr><td>Jen</td><td>Finance</td><td>3900</td><td>10200</td></tr>\n",
       "<tr><td>Kumar</td><td>Marketing</td><td>2000</td><td>2000</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>3000</td><td>5000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+----------+------+------+\n",
       "|employee|department|salary|cumsum|\n",
       "+--------+----------+------+------+\n",
       "|   James|     Sales|  3000|  9000|\n",
       "|     Ash|     Sales|  3000|  9000|\n",
       "|   Wayne|     Sales|  3000|  9000|\n",
       "|   Harry|     Sales|  3500| 12500|\n",
       "|  Robert|     Sales|  4100| 20700|\n",
       "|    Saif|     Sales|  4100| 20700|\n",
       "| Michael|     Sales|  4600| 25300|\n",
       "|   Maria|   Finance|  3000|  3000|\n",
       "|   Scott|   Finance|  3300|  6300|\n",
       "|     Jen|   Finance|  3900| 10200|\n",
       "|   Kumar| Marketing|  2000|  2000|\n",
       "|    Jeff| Marketing|  3000|  5000|\n",
       "+--------+----------+------+------+"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\\\n",
    "    .withColumn('cumsum', F.sum('salary').over(window))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Unpivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>color</th><th>small</th><th>medium</th><th>large</th></tr>\n",
       "<tr><td>red</td><td>1000</td><td>1200</td><td>1500</td></tr>\n",
       "<tr><td>green</td><td>1500</td><td>1500</td><td>1575</td></tr>\n",
       "<tr><td>blue</td><td>2000</td><td>2200</td><td>2000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+-----+------+-----+\n",
       "|color|small|medium|large|\n",
       "+-----+-----+------+-----+\n",
       "|  red| 1000|  1200| 1500|\n",
       "|green| 1500|  1500| 1575|\n",
       "| blue| 2000|  2200| 2000|\n",
       "+-----+-----+------+-----+"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    ('red', 1000, 1200, 1500),\n",
    "    ('green', 1500, 1500, 1575),\n",
    "    ('blue', 2000, 2200, 2000)\n",
    ")\n",
    "\n",
    "columns = ['color', 'small', 'medium', 'large']\n",
    "\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>color</th><th>size</th><th>price</th></tr>\n",
       "<tr><td>red</td><td>small</td><td>1000</td></tr>\n",
       "<tr><td>red</td><td>medium</td><td>1200</td></tr>\n",
       "<tr><td>red</td><td>large</td><td>1500</td></tr>\n",
       "<tr><td>green</td><td>small</td><td>1500</td></tr>\n",
       "<tr><td>green</td><td>medium</td><td>1500</td></tr>\n",
       "<tr><td>green</td><td>large</td><td>1575</td></tr>\n",
       "<tr><td>blue</td><td>small</td><td>2000</td></tr>\n",
       "<tr><td>blue</td><td>medium</td><td>2200</td></tr>\n",
       "<tr><td>blue</td><td>large</td><td>2000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+------+-----+\n",
       "|color|  size|price|\n",
       "+-----+------+-----+\n",
       "|  red| small| 1000|\n",
       "|  red|medium| 1200|\n",
       "|  red| large| 1500|\n",
       "|green| small| 1500|\n",
       "|green|medium| 1500|\n",
       "|green| large| 1575|\n",
       "| blue| small| 2000|\n",
       "| blue|medium| 2200|\n",
       "| blue| large| 2000|\n",
       "+-----+------+-----+"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('color', F.expr('stack(3, \"small\", small, \"medium\", medium, \"large\", large) as (size, price)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>invoice_id</th><th>brand</th><th>city</th><th>customer_type</th><th>gender</th><th>product_line</th><th>unit_price</th><th>quantity</th><th>tax</th><th>date</th><th>time</th><th>payment</th><th>cost</th><th>gross_margin_percentage</th><th>profit</th><th>rating</th></tr>\n",
       "<tr><td>750-67-8428</td><td>A</td><td>Yangon</td><td>Member</td><td>Female</td><td>Health and beauty</td><td>74.69</td><td>7</td><td>26.1415</td><td>01/05/2019</td><td>13:08</td><td>Ewallet</td><td>522.83</td><td>4.761904762</td><td>26.1415</td><td>9.1</td></tr>\n",
       "<tr><td>226-31-3081</td><td>C</td><td>Naypyitaw</td><td>Normal</td><td>Female</td><td>Electronic access...</td><td>15.28</td><td>5</td><td>3.82</td><td>03/08/2019</td><td>10:29</td><td>Cash</td><td>76.4</td><td>4.761904762</td><td>3.82</td><td>9.6</td></tr>\n",
       "<tr><td>631-41-3108</td><td>A</td><td>Yangon</td><td>Normal</td><td>Male</td><td>Home and lifestyle</td><td>46.33</td><td>7</td><td>16.2155</td><td>03/03/2019</td><td>13:23</td><td>Credit card</td><td>324.31</td><td>4.761904762</td><td>16.2155</td><td>7.4</td></tr>\n",
       "<tr><td>123-19-1176</td><td>A</td><td>Yangon</td><td>Member</td><td>Male</td><td>Health and beauty</td><td>58.22</td><td>8</td><td>23.288</td><td>1/27/2019</td><td>20:33</td><td>Ewallet</td><td>465.76</td><td>4.761904762</td><td>23.288</td><td>8.4</td></tr>\n",
       "<tr><td>373-73-7910</td><td>A</td><td>Yangon</td><td>Normal</td><td>Male</td><td>Sports and travel</td><td>86.31</td><td>7</td><td>30.2085</td><td>02/08/2019</td><td>10:37</td><td>Ewallet</td><td>604.17</td><td>4.761904762</td><td>30.2085</td><td>5.3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+\n",
       "| invoice_id|brand|     city|customer_type|gender|        product_line|unit_price|quantity|    tax|      date| time|    payment|  cost|gross_margin_percentage| profit|rating|\n",
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+\n",
       "|750-67-8428|    A|   Yangon|       Member|Female|   Health and beauty|     74.69|       7|26.1415|01/05/2019|13:08|    Ewallet|522.83|            4.761904762|26.1415|   9.1|\n",
       "|226-31-3081|    C|Naypyitaw|       Normal|Female|Electronic access...|     15.28|       5|   3.82|03/08/2019|10:29|       Cash|  76.4|            4.761904762|   3.82|   9.6|\n",
       "|631-41-3108|    A|   Yangon|       Normal|  Male|  Home and lifestyle|     46.33|       7|16.2155|03/03/2019|13:23|Credit card|324.31|            4.761904762|16.2155|   7.4|\n",
       "|123-19-1176|    A|   Yangon|       Member|  Male|   Health and beauty|     58.22|       8| 23.288| 1/27/2019|20:33|    Ewallet|465.76|            4.761904762| 23.288|   8.4|\n",
       "|373-73-7910|    A|   Yangon|       Normal|  Male|   Sports and travel|     86.31|       7|30.2085|02/08/2019|10:37|    Ewallet|604.17|            4.761904762|30.2085|   5.3|\n",
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supermarket = spark.read.csv(r'data\\supermarket_sales.csv', header=True)\n",
    "supermarket.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product_line</th><th>Mandalay</th><th>Naypyitaw</th><th>Yangon</th></tr>\n",
       "<tr><td>Home and lifestyle</td><td>16.71</td><td>14.7</td><td>16.42</td></tr>\n",
       "<tr><td>Fashion accessories</td><td>12.61</td><td>15.79</td><td>15.25</td></tr>\n",
       "<tr><td>Health and beauty</td><td>17.95</td><td>15.22</td><td>12.76</td></tr>\n",
       "<tr><td>Electronic access...</td><td>14.76</td><td>16.42</td><td>14.54</td></tr>\n",
       "<tr><td>Food and beverages</td><td>14.49</td><td>17.15</td><td>14.09</td></tr>\n",
       "<tr><td>Sports and travel</td><td>15.35</td><td>16.68</td><td>15.64</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+--------+---------+------+\n",
       "|        product_line|Mandalay|Naypyitaw|Yangon|\n",
       "+--------------------+--------+---------+------+\n",
       "|  Home and lifestyle|   16.71|     14.7| 16.42|\n",
       "| Fashion accessories|   12.61|    15.79| 15.25|\n",
       "|   Health and beauty|   17.95|    15.22| 12.76|\n",
       "|Electronic access...|   14.76|    16.42| 14.54|\n",
       "|  Food and beverages|   14.49|    17.15| 14.09|\n",
       "|   Sports and travel|   15.35|    16.68| 15.64|\n",
       "+--------------------+--------+---------+------+"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supermarket\\\n",
    "    .groupBy('product_line')\\\n",
    "    .pivot('city')\\\n",
    "    .agg(F.round(F.mean('profit'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product_line</th><th>Female, Member</th><th>Female, Normal</th><th>Male, Member</th><th>Male, Normal</th></tr>\n",
       "<tr><td>Home and lifestyle</td><td>17.46</td><td>19.05</td><td>14.21</td><td>13.84</td></tr>\n",
       "<tr><td>Fashion accessories</td><td>15.32</td><td>14.88</td><td>13.68</td><td>14.03</td></tr>\n",
       "<tr><td>Health and beauty</td><td>13.3</td><td>14.26</td><td>19.33</td><td>13.95</td></tr>\n",
       "<tr><td>Electronic access...</td><td>15.17</td><td>15.5</td><td>14.78</td><td>15.38</td></tr>\n",
       "<tr><td>Food and beverages</td><td>18.3</td><td>16.57</td><td>13.02</td><td>13.03</td></tr>\n",
       "<tr><td>Sports and travel</td><td>15.55</td><td>15.34</td><td>15.31</td><td>16.98</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+--------------+--------------+------------+------------+\n",
       "|        product_line|Female, Member|Female, Normal|Male, Member|Male, Normal|\n",
       "+--------------------+--------------+--------------+------------+------------+\n",
       "|  Home and lifestyle|         17.46|         19.05|       14.21|       13.84|\n",
       "| Fashion accessories|         15.32|         14.88|       13.68|       14.03|\n",
       "|   Health and beauty|          13.3|         14.26|       19.33|       13.95|\n",
       "|Electronic access...|         15.17|          15.5|       14.78|       15.38|\n",
       "|  Food and beverages|          18.3|         16.57|       13.02|       13.03|\n",
       "|   Sports and travel|         15.55|         15.34|       15.31|       16.98|\n",
       "+--------------------+--------------+--------------+------------+------------+"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supermarket\\\n",
    "    .withColumn('info', F.concat(F.col('gender'), F.lit(', '), F.col('customer_type')))\\\n",
    "    .groupBy('product_line')\\\n",
    "    .pivot('info')\\\n",
    "    .agg(F.round(F.mean('profit'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Crosstab\n",
    "Crosstab is a special case of pivot table, where `count` is selected as the aggregate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>invoice_id</th><th>brand</th><th>city</th><th>customer_type</th><th>gender</th><th>product_line</th><th>unit_price</th><th>quantity</th><th>tax</th><th>date</th><th>time</th><th>payment</th><th>cost</th><th>gross_margin_percentage</th><th>profit</th><th>rating</th></tr>\n",
       "<tr><td>750-67-8428</td><td>A</td><td>Yangon</td><td>Member</td><td>Female</td><td>Health and beauty</td><td>74.69</td><td>7</td><td>26.1415</td><td>01/05/2019</td><td>13:08</td><td>Ewallet</td><td>522.83</td><td>4.761904762</td><td>26.1415</td><td>9.1</td></tr>\n",
       "<tr><td>226-31-3081</td><td>C</td><td>Naypyitaw</td><td>Normal</td><td>Female</td><td>Electronic access...</td><td>15.28</td><td>5</td><td>3.82</td><td>03/08/2019</td><td>10:29</td><td>Cash</td><td>76.4</td><td>4.761904762</td><td>3.82</td><td>9.6</td></tr>\n",
       "<tr><td>631-41-3108</td><td>A</td><td>Yangon</td><td>Normal</td><td>Male</td><td>Home and lifestyle</td><td>46.33</td><td>7</td><td>16.2155</td><td>03/03/2019</td><td>13:23</td><td>Credit card</td><td>324.31</td><td>4.761904762</td><td>16.2155</td><td>7.4</td></tr>\n",
       "<tr><td>123-19-1176</td><td>A</td><td>Yangon</td><td>Member</td><td>Male</td><td>Health and beauty</td><td>58.22</td><td>8</td><td>23.288</td><td>1/27/2019</td><td>20:33</td><td>Ewallet</td><td>465.76</td><td>4.761904762</td><td>23.288</td><td>8.4</td></tr>\n",
       "<tr><td>373-73-7910</td><td>A</td><td>Yangon</td><td>Normal</td><td>Male</td><td>Sports and travel</td><td>86.31</td><td>7</td><td>30.2085</td><td>02/08/2019</td><td>10:37</td><td>Ewallet</td><td>604.17</td><td>4.761904762</td><td>30.2085</td><td>5.3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+\n",
       "| invoice_id|brand|     city|customer_type|gender|        product_line|unit_price|quantity|    tax|      date| time|    payment|  cost|gross_margin_percentage| profit|rating|\n",
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+\n",
       "|750-67-8428|    A|   Yangon|       Member|Female|   Health and beauty|     74.69|       7|26.1415|01/05/2019|13:08|    Ewallet|522.83|            4.761904762|26.1415|   9.1|\n",
       "|226-31-3081|    C|Naypyitaw|       Normal|Female|Electronic access...|     15.28|       5|   3.82|03/08/2019|10:29|       Cash|  76.4|            4.761904762|   3.82|   9.6|\n",
       "|631-41-3108|    A|   Yangon|       Normal|  Male|  Home and lifestyle|     46.33|       7|16.2155|03/03/2019|13:23|Credit card|324.31|            4.761904762|16.2155|   7.4|\n",
       "|123-19-1176|    A|   Yangon|       Member|  Male|   Health and beauty|     58.22|       8| 23.288| 1/27/2019|20:33|    Ewallet|465.76|            4.761904762| 23.288|   8.4|\n",
       "|373-73-7910|    A|   Yangon|       Normal|  Male|   Sports and travel|     86.31|       7|30.2085|02/08/2019|10:37|    Ewallet|604.17|            4.761904762|30.2085|   5.3|\n",
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supermarket = spark.read.csv(r'data\\supermarket_sales.csv', header=True)\n",
    "supermarket.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>city_payment</th><th>Cash</th><th>Credit card</th><th>Ewallet</th></tr>\n",
       "<tr><td>Naypyitaw</td><td>124</td><td>98</td><td>106</td></tr>\n",
       "<tr><td>Mandalay</td><td>110</td><td>109</td><td>113</td></tr>\n",
       "<tr><td>Yangon</td><td>110</td><td>104</td><td>126</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+----+-----------+-------+\n",
       "|city_payment|Cash|Credit card|Ewallet|\n",
       "+------------+----+-----------+-------+\n",
       "|   Naypyitaw| 124|         98|    106|\n",
       "|    Mandalay| 110|        109|    113|\n",
       "|      Yangon| 110|        104|    126|\n",
       "+------------+----+-----------+-------+"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supermarket.crosstab('city', 'payment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Combining datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Union\n",
    "PySpark supports two union methods:\n",
    "- `union`: union using the current order of columns\n",
    "- `unionByName`: union using column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>quarter</th><th>profit</th></tr>\n",
       "<tr><td>2019</td><td>1</td><td>2500</td></tr>\n",
       "<tr><td>2019</td><td>2</td><td>3500</td></tr>\n",
       "<tr><td>2019</td><td>3</td><td>4000</td></tr>\n",
       "<tr><td>2019</td><td>4</td><td>5000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+------+\n",
       "|year|quarter|profit|\n",
       "+----+-------+------+\n",
       "|2019|      1|  2500|\n",
       "|2019|      2|  3500|\n",
       "|2019|      3|  4000|\n",
       "|2019|      4|  5000|\n",
       "+----+-------+------+"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    (2019, 1, 2500),\n",
    "    (2019, 2, 3500),\n",
    "    (2019, 3, 4000),\n",
    "    (2019, 4, 5000)\n",
    ")\n",
    "\n",
    "columns = ['year', 'quarter', 'profit']\n",
    "\n",
    "df_19 = spark.createDataFrame(data, schema=columns)\n",
    "df_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>quarter</th><th>profit</th></tr>\n",
       "<tr><td>2020</td><td>1</td><td>2700</td></tr>\n",
       "<tr><td>2020</td><td>2</td><td>3900</td></tr>\n",
       "<tr><td>2020</td><td>3</td><td>5000</td></tr>\n",
       "<tr><td>2020</td><td>4</td><td>8000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+------+\n",
       "|year|quarter|profit|\n",
       "+----+-------+------+\n",
       "|2020|      1|  2700|\n",
       "|2020|      2|  3900|\n",
       "|2020|      3|  5000|\n",
       "|2020|      4|  8000|\n",
       "+----+-------+------+"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    (2020, 1, 2700),\n",
    "    (2020, 2, 3900),\n",
    "    (2020, 3, 5000),\n",
    "    (2020, 4, 8000)\n",
    ")\n",
    "\n",
    "columns = ['year', 'quarter', 'profit']\n",
    "\n",
    "df_20 = spark.createDataFrame(data, schema=columns)\n",
    "df_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>quarter</th><th>profit</th></tr>\n",
       "<tr><td>2019</td><td>1</td><td>2500</td></tr>\n",
       "<tr><td>2019</td><td>2</td><td>3500</td></tr>\n",
       "<tr><td>2019</td><td>3</td><td>4000</td></tr>\n",
       "<tr><td>2019</td><td>4</td><td>5000</td></tr>\n",
       "<tr><td>2020</td><td>1</td><td>2700</td></tr>\n",
       "<tr><td>2020</td><td>2</td><td>3900</td></tr>\n",
       "<tr><td>2020</td><td>3</td><td>5000</td></tr>\n",
       "<tr><td>2020</td><td>4</td><td>8000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+------+\n",
       "|year|quarter|profit|\n",
       "+----+-------+------+\n",
       "|2019|      1|  2500|\n",
       "|2019|      2|  3500|\n",
       "|2019|      3|  4000|\n",
       "|2019|      4|  5000|\n",
       "|2020|      1|  2700|\n",
       "|2020|      2|  3900|\n",
       "|2020|      3|  5000|\n",
       "|2020|      4|  8000|\n",
       "+----+-------+------+"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_19.union(df_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>quarter</th><th>profit</th></tr>\n",
       "<tr><td>2019</td><td>1</td><td>2500</td></tr>\n",
       "<tr><td>2019</td><td>2</td><td>3500</td></tr>\n",
       "<tr><td>2019</td><td>3</td><td>4000</td></tr>\n",
       "<tr><td>2019</td><td>4</td><td>5000</td></tr>\n",
       "<tr><td>2020</td><td>1</td><td>2700</td></tr>\n",
       "<tr><td>2020</td><td>2</td><td>3900</td></tr>\n",
       "<tr><td>2020</td><td>3</td><td>5000</td></tr>\n",
       "<tr><td>2020</td><td>4</td><td>8000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+------+\n",
       "|year|quarter|profit|\n",
       "+----+-------+------+\n",
       "|2019|      1|  2500|\n",
       "|2019|      2|  3500|\n",
       "|2019|      3|  4000|\n",
       "|2019|      4|  5000|\n",
       "|2020|      1|  2700|\n",
       "|2020|      2|  3900|\n",
       "|2020|      3|  5000|\n",
       "|2020|      4|  8000|\n",
       "+----+-------+------+"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_19.unionByName(df_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>income_before_tax</th><th>tax_band</th></tr>\n",
       "<tr><td>Hannah</td><td>1200</td><td>Allowance</td></tr>\n",
       "<tr><td>James</td><td>3000</td><td>Basic</td></tr>\n",
       "<tr><td>Gabriel</td><td>700</td><td>Allowance</td></tr>\n",
       "<tr><td>Smith</td><td>2000</td><td>Basic</td></tr>\n",
       "<tr><td>Alex</td><td>10000</td><td>Higher</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-----------------+---------+\n",
       "|   name|income_before_tax| tax_band|\n",
       "+-------+-----------------+---------+\n",
       "| Hannah|             1200|Allowance|\n",
       "|  James|             3000|    Basic|\n",
       "|Gabriel|              700|Allowance|\n",
       "|  Smith|             2000|    Basic|\n",
       "|   Alex|            10000|   Higher|\n",
       "+-------+-----------------+---------+"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    ('Hannah', 1200, 'Allowance'),\n",
    "    ('James', 3000, 'Basic'),\n",
    "    ('Gabriel', 700, 'Allowance'),\n",
    "    ('Smith', 2000, 'Basic'),\n",
    "    ('Alex', 10000, 'Higher'),\n",
    ")\n",
    "\n",
    "columns = ['name', 'income_before_tax', 'tax_band']\n",
    "\n",
    "income = spark.createDataFrame(data, schema=columns)\n",
    "income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>band</th><th>income_range</th><th>tax_rate</th></tr>\n",
       "<tr><td>Allowance</td><td>Up to 12,500</td><td>0.0</td></tr>\n",
       "<tr><td>Basic</td><td>12,501 to 50,000</td><td>0.2</td></tr>\n",
       "<tr><td>Higher</td><td>50,001 to 150,000</td><td>0.4</td></tr>\n",
       "<tr><td>Additional</td><td>Over 150,000</td><td>0.45</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+-----------------+--------+\n",
       "|      band|     income_range|tax_rate|\n",
       "+----------+-----------------+--------+\n",
       "| Allowance|     Up to 12,500|     0.0|\n",
       "|     Basic| 12,501 to 50,000|     0.2|\n",
       "|    Higher|50,001 to 150,000|     0.4|\n",
       "|Additional|     Over 150,000|    0.45|\n",
       "+----------+-----------------+--------+"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    ('Allowance', 'Up to 12,500', 0.0),\n",
    "    ('Basic', '12,501 to 50,000', 0.2),\n",
    "    ('Higher', '50,001 to 150,000', 0.4),\n",
    "    ('Additional', 'Over 150,000', 0.45),\n",
    ")\n",
    "\n",
    "columns = ['band', 'income_range', 'tax_rate']\n",
    "\n",
    "tax = spark.createDataFrame(data, columns)\n",
    "tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>income_before_tax</th><th>tax_band</th><th>band</th><th>income_range</th><th>tax_rate</th></tr>\n",
       "<tr><td>Hannah</td><td>1200</td><td>Allowance</td><td>Allowance</td><td>Up to 12,500</td><td>0.0</td></tr>\n",
       "<tr><td>Gabriel</td><td>700</td><td>Allowance</td><td>Allowance</td><td>Up to 12,500</td><td>0.0</td></tr>\n",
       "<tr><td>Alex</td><td>10000</td><td>Higher</td><td>Higher</td><td>50,001 to 150,000</td><td>0.4</td></tr>\n",
       "<tr><td>James</td><td>3000</td><td>Basic</td><td>Basic</td><td>12,501 to 50,000</td><td>0.2</td></tr>\n",
       "<tr><td>Smith</td><td>2000</td><td>Basic</td><td>Basic</td><td>12,501 to 50,000</td><td>0.2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-----------------+---------+---------+-----------------+--------+\n",
       "|   name|income_before_tax| tax_band|     band|     income_range|tax_rate|\n",
       "+-------+-----------------+---------+---------+-----------------+--------+\n",
       "| Hannah|             1200|Allowance|Allowance|     Up to 12,500|     0.0|\n",
       "|Gabriel|              700|Allowance|Allowance|     Up to 12,500|     0.0|\n",
       "|   Alex|            10000|   Higher|   Higher|50,001 to 150,000|     0.4|\n",
       "|  James|             3000|    Basic|    Basic| 12,501 to 50,000|     0.2|\n",
       "|  Smith|             2000|    Basic|    Basic| 12,501 to 50,000|     0.2|\n",
       "+-------+-----------------+---------+---------+-----------------+--------+"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income.join(tax, income.tax_band==tax.band, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>band</th><th>name</th><th>income_before_tax</th><th>income_range</th><th>tax_rate</th></tr>\n",
       "<tr><td>Allowance</td><td>Hannah</td><td>1200</td><td>Up to 12,500</td><td>0.0</td></tr>\n",
       "<tr><td>Allowance</td><td>Gabriel</td><td>700</td><td>Up to 12,500</td><td>0.0</td></tr>\n",
       "<tr><td>Higher</td><td>Alex</td><td>10000</td><td>50,001 to 150,000</td><td>0.4</td></tr>\n",
       "<tr><td>Basic</td><td>James</td><td>3000</td><td>12,501 to 50,000</td><td>0.2</td></tr>\n",
       "<tr><td>Basic</td><td>Smith</td><td>2000</td><td>12,501 to 50,000</td><td>0.2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+-------+-----------------+-----------------+--------+\n",
       "|     band|   name|income_before_tax|     income_range|tax_rate|\n",
       "+---------+-------+-----------------+-----------------+--------+\n",
       "|Allowance| Hannah|             1200|     Up to 12,500|     0.0|\n",
       "|Allowance|Gabriel|              700|     Up to 12,500|     0.0|\n",
       "|   Higher|   Alex|            10000|50,001 to 150,000|     0.4|\n",
       "|    Basic|  James|             3000| 12,501 to 50,000|     0.2|\n",
       "|    Basic|  Smith|             2000| 12,501 to 50,000|     0.2|\n",
       "+---------+-------+-----------------+-----------------+--------+"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income\\\n",
    "    .withColumnRenamed('tax_band', 'band')\\\n",
    "    .join(tax, on='band', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Working with arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:35:51.167742Z",
     "iopub.status.busy": "2021-07-02T17:35:51.163772Z",
     "iopub.status.idle": "2021-07-02T17:36:01.731838Z",
     "shell.execute_reply": "2021-07-02T17:36:01.730817Z",
     "shell.execute_reply.started": "2021-07-02T17:35:51.167742Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "spark.conf.set('spark.sql.repl.eagerEval.truncate', 1000)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sspipe import p, px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe with array-type columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>languagesAtSchool</th><th>languagesAtWork</th><th>currentState</th><th>previousState</th></tr>\n",
       "<tr><td>James Smith</td><td>[Java, Scala, C++, R]</td><td>[Spark, Java]</td><td>OH</td><td>CA</td></tr>\n",
       "<tr><td>Michael Rose</td><td>[Spark, Java, C++, Python, Ruby]</td><td>[Spark, Java]</td><td>NY</td><td>NJ</td></tr>\n",
       "<tr><td>Robert Williams</td><td>[CSharp, VB, Python, R, Julia]</td><td>[Spark, Python]</td><td>UT</td><td>NV</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+--------------------------------+---------------+------------+-------------+\n",
       "|           name|               languagesAtSchool|languagesAtWork|currentState|previousState|\n",
       "+---------------+--------------------------------+---------------+------------+-------------+\n",
       "|    James Smith|           [Java, Scala, C++, R]|  [Spark, Java]|          OH|           CA|\n",
       "|   Michael Rose|[Spark, Java, C++, Python, Ruby]|  [Spark, Java]|          NY|           NJ|\n",
       "|Robert Williams|  [CSharp, VB, Python, R, Julia]|[Spark, Python]|          UT|           NV|\n",
       "+---------------+--------------------------------+---------------+------------+-------------+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    " (\"James Smith\",[\"Java\",\"Scala\",\"C++\", \"R\"],[\"Spark\",\"Java\"],\"OH\",\"CA\"),\n",
    " (\"Michael Rose\",[\"Spark\",\"Java\",\"C++\", \"Python\", \"Ruby\"],[\"Spark\",\"Java\"],\"NY\",\"NJ\"),\n",
    " (\"Robert Williams\",[\"CSharp\",\"VB\", \"Python\", \"R\", \"Julia\"],[\"Spark\",\"Python\"],\"UT\",\"NV\")\n",
    "]\n",
    "\n",
    "from pyspark.sql.types import StringType, ArrayType,StructType,StructField\n",
    "schema = StructType([ \n",
    "    StructField(\"name\",StringType(),True), \n",
    "    StructField(\"languagesAtSchool\",ArrayType(StringType()),True), \n",
    "    StructField(\"languagesAtWork\",ArrayType(StringType()),True), \n",
    "    StructField(\"currentState\", StringType(), True), \n",
    "    StructField(\"previousState\", StringType(), True)\n",
    "  ])\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### explode: transform array to rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>language</th></tr>\n",
       "<tr><td>James Smith</td><td>Java</td></tr>\n",
       "<tr><td>James Smith</td><td>Scala</td></tr>\n",
       "<tr><td>James Smith</td><td>C++</td></tr>\n",
       "<tr><td>James Smith</td><td>R</td></tr>\n",
       "<tr><td>Michael Rose</td><td>Spark</td></tr>\n",
       "<tr><td>Michael Rose</td><td>Java</td></tr>\n",
       "<tr><td>Michael Rose</td><td>C++</td></tr>\n",
       "<tr><td>Michael Rose</td><td>Python</td></tr>\n",
       "<tr><td>Michael Rose</td><td>Ruby</td></tr>\n",
       "<tr><td>Robert Williams</td><td>CSharp</td></tr>\n",
       "<tr><td>Robert Williams</td><td>VB</td></tr>\n",
       "<tr><td>Robert Williams</td><td>Python</td></tr>\n",
       "<tr><td>Robert Williams</td><td>R</td></tr>\n",
       "<tr><td>Robert Williams</td><td>Julia</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+--------+\n",
       "|           name|language|\n",
       "+---------------+--------+\n",
       "|    James Smith|    Java|\n",
       "|    James Smith|   Scala|\n",
       "|    James Smith|     C++|\n",
       "|    James Smith|       R|\n",
       "|   Michael Rose|   Spark|\n",
       "|   Michael Rose|    Java|\n",
       "|   Michael Rose|     C++|\n",
       "|   Michael Rose|  Python|\n",
       "|   Michael Rose|    Ruby|\n",
       "|Robert Williams|  CSharp|\n",
       "|Robert Williams|      VB|\n",
       "|Robert Williams|  Python|\n",
       "|Robert Williams|       R|\n",
       "|Robert Williams|   Julia|\n",
       "+---------------+--------+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_explode = df.select('name', F.explode('languagesAtSchool').alias('language'))\n",
    "df_explode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groupby + collect_list: reverse transformation of explode, but with a random order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>languages</th></tr>\n",
       "<tr><td>James Smith</td><td>[Java, Scala, C++, R]</td></tr>\n",
       "<tr><td>Robert Williams</td><td>[CSharp, VB, Python, R, Julia]</td></tr>\n",
       "<tr><td>Michael Rose</td><td>[Spark, Java, C++, Python, Ruby]</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+--------------------------------+\n",
       "|           name|                       languages|\n",
       "+---------------+--------------------------------+\n",
       "|    James Smith|           [Java, Scala, C++, R]|\n",
       "|Robert Williams|  [CSharp, VB, Python, R, Julia]|\n",
       "|   Michael Rose|[Spark, Java, C++, Python, Ruby]|\n",
       "+---------------+--------------------------------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_explode.groupby('name').agg(F.collect_list('language').alias('languages'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>k</th><th>language</th></tr>\n",
       "<tr><td>James Smith</td><td>[{C++, 1}, {Java, 2}, {R, 3}, {Scala, 4}]</td><td>[C++, Java, R, Scala]</td></tr>\n",
       "<tr><td>Robert Williams</td><td>[{CSharp, 1}, {Julia, 2}, {Python, 3}, {R, 4}, {VB, 5}]</td><td>[CSharp, Julia, Python, R, VB]</td></tr>\n",
       "<tr><td>Michael Rose</td><td>[{C++, 1}, {Java, 2}, {Python, 3}, {Ruby, 4}, {Spark, 5}]</td><td>[C++, Java, Python, Ruby, Spark]</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+---------------------------------------------------------+--------------------------------+\n",
       "|           name|                                                        k|                        language|\n",
       "+---------------+---------------------------------------------------------+--------------------------------+\n",
       "|    James Smith|                [{C++, 1}, {Java, 2}, {R, 3}, {Scala, 4}]|           [C++, Java, R, Scala]|\n",
       "|Robert Williams|  [{CSharp, 1}, {Julia, 2}, {Python, 3}, {R, 4}, {VB, 5}]|  [CSharp, Julia, Python, R, VB]|\n",
       "|   Michael Rose|[{C++, 1}, {Java, 2}, {Python, 3}, {Ruby, 4}, {Spark, 5}]|[C++, Java, Python, Ruby, Spark]|\n",
       "+---------------+---------------------------------------------------------+--------------------------------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_explode\\\n",
    "    .withColumn('rank', F.expr('ROW_NUMBER() OVER (PARTITION BY name ORDER BY language ASC)'))\\\n",
    "    .groupBy('name').agg(F.collect_list(F.struct('language', 'rank')).alias('k'))\\\n",
    "    .withColumn('k', F.sort_array('k'))\\\n",
    "    .withColumn('language', F.col('k.language'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split a column into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name_array</th></tr>\n",
       "<tr><td>[James, Smith]</td></tr>\n",
       "<tr><td>[Michael, Rose]</td></tr>\n",
       "<tr><td>[Robert, Williams]</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------------+\n",
       "|        name_array|\n",
       "+------------------+\n",
       "|    [James, Smith]|\n",
       "|   [Michael, Rose]|\n",
       "|[Robert, Williams]|\n",
       "+------------------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split = df.select(F.split('name', ' ').alias('name_array'))\n",
    "df_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reverse splitting, using array join and regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>array_join(name_array, _)</th></tr>\n",
       "<tr><td>James_Smith</td></tr>\n",
       "<tr><td>Michael_Rose</td></tr>\n",
       "<tr><td>Robert_Williams</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------------+\n",
       "|array_join(name_array, _)|\n",
       "+-------------------------+\n",
       "|              James_Smith|\n",
       "|             Michael_Rose|\n",
       "|          Robert_Williams|\n",
       "+-------------------------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split.select(F.array_join('name_array', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th></tr>\n",
       "<tr><td>James Smith</td></tr>\n",
       "<tr><td>Michael Rose</td></tr>\n",
       "<tr><td>Robert Williams</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+\n",
       "|           name|\n",
       "+---------------+\n",
       "|    James Smith|\n",
       "|   Michael Rose|\n",
       "|Robert Williams|\n",
       "+---------------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split\\\n",
    "    .selectExpr('CAST (name_array AS string)')\\\n",
    "    .select(F.regexp_replace('name_array', r'\\[|\\]|,', '').alias('name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly select n elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>languagesAtSchool</th><th>languagesAtWork</th><th>currentState</th><th>previousState</th></tr>\n",
       "<tr><td>James Smith</td><td>[Java, Scala, C++, R]</td><td>[Spark, Java]</td><td>OH</td><td>CA</td></tr>\n",
       "<tr><td>Michael Rose</td><td>[Spark, Java, C++, Python, Ruby]</td><td>[Spark, Java]</td><td>NY</td><td>NJ</td></tr>\n",
       "<tr><td>Robert Williams</td><td>[CSharp, VB, Python, R, Julia]</td><td>[Spark, Python]</td><td>UT</td><td>NV</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "DataFrame[name: string, languagesAtSchool: array<string>, languagesAtWork: array<string>, currentState: string, previousState: string]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>random_languages</th><th>rank</th></tr>\n",
       "<tr><td>James Smith</td><td>[C++, Scala]</td><td>1</td></tr>\n",
       "<tr><td>Michael Rose</td><td>[Python, C++]</td><td>2</td></tr>\n",
       "<tr><td>Robert Williams</td><td>[VB, Julia]</td><td>3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+----------------+----+\n",
       "|           name|random_languages|rank|\n",
       "+---------------+----------------+----+\n",
       "|    James Smith|    [C++, Scala]|   1|\n",
       "|   Michael Rose|   [Python, C++]|   2|\n",
       "|Robert Williams|     [VB, Julia]|   3|\n",
       "+---------------+----------------+----+"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\\\n",
    "    .selectExpr('name', 'SLICE(SHUFFLE(languagesAtSchool), 1, 2) AS random_languages')\\\n",
    "    .withColumn('rank', F.expr('ROW_NUMBER() OVER (ORDER BY name)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>random_languages</th><th>rank</th><th>language</th></tr>\n",
       "<tr><td>James Smith</td><td>[C++, R]</td><td>1</td><td>C++</td></tr>\n",
       "<tr><td>James Smith</td><td>[C++, R]</td><td>1</td><td>R</td></tr>\n",
       "<tr><td>Michael Rose</td><td>[C++, Python]</td><td>2</td><td>C++</td></tr>\n",
       "<tr><td>Michael Rose</td><td>[C++, Python]</td><td>2</td><td>Python</td></tr>\n",
       "<tr><td>Robert Williams</td><td>[R, VB]</td><td>3</td><td>R</td></tr>\n",
       "<tr><td>Robert Williams</td><td>[R, VB]</td><td>3</td><td>VB</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+----------------+----+--------+\n",
       "|           name|random_languages|rank|language|\n",
       "+---------------+----------------+----+--------+\n",
       "|    James Smith|        [C++, R]|   1|     C++|\n",
       "|    James Smith|        [C++, R]|   1|       R|\n",
       "|   Michael Rose|   [C++, Python]|   2|     C++|\n",
       "|   Michael Rose|   [C++, Python]|   2|  Python|\n",
       "|Robert Williams|         [R, VB]|   3|       R|\n",
       "|Robert Williams|         [R, VB]|   3|      VB|\n",
       "+---------------+----------------+----+--------+"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\\\n",
    "    .withColumn('rank', F.expr('ROW_NUMBER() OVER (ORDER BY name)'))\\\n",
    "    .selectExpr('name', 'SLICE(SHUFFLE(languagesAtSchool), 1, 2) AS random_languages', 'rank')\\\n",
    "    .withColumn('language', F.explode('random_languages'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate two arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>union</th></tr>\n",
       "<tr><td>[Java, Scala, C++, R, Spark]</td></tr>\n",
       "<tr><td>[Spark, Java, C++, Python, Ruby]</td></tr>\n",
       "<tr><td>[CSharp, VB, Python, R, Julia, Spark]</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------------------------+\n",
       "|                                union|\n",
       "+-------------------------------------+\n",
       "|         [Java, Scala, C++, R, Spark]|\n",
       "|     [Spark, Java, C++, Python, Ruby]|\n",
       "|[CSharp, VB, Python, R, Julia, Spark]|\n",
       "+-------------------------------------+"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(F.array_union('languagesAtSchool', 'languagesAtWork').alias('union'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>intersect</th></tr>\n",
       "<tr><td>[Java]</td></tr>\n",
       "<tr><td>[Spark, Java]</td></tr>\n",
       "<tr><td>[Python]</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+\n",
       "|    intersect|\n",
       "+-------------+\n",
       "|       [Java]|\n",
       "|[Spark, Java]|\n",
       "|     [Python]|\n",
       "+-------------+"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(F.array_intersect('languagesAtSchool', 'languagesAtWork').alias('intersect'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>array_sort(languagesAtSchool, lambdafunction((IF(((left IS NULL) AND (right IS NULL)), 0, (IF((left IS NULL), 1, (IF((right IS NULL), -1, (IF((left &lt; right), -1, (IF((left &gt; right), 1, 0)))))))))), left, right))</th></tr>\n",
       "<tr><td>[C++, Java, R, Scala]</td></tr>\n",
       "<tr><td>[C++, Java, Python, Ruby, Spark]</td></tr>\n",
       "<tr><td>[CSharp, Julia, Python, R, VB]</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
       "|array_sort(languagesAtSchool, lambdafunction((IF(((left IS NULL) AND (right IS NULL)), 0, (IF((left IS NULL), 1, (IF((right IS NULL), -1, (IF((left < right), -1, (IF((left > right), 1, 0)))))))))), left, right))|\n",
       "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
       "|                                                                                                                                                                                              [C++, Java, R, Scala]|\n",
       "|                                                                                                                                                                                   [C++, Java, Python, Ruby, Spark]|\n",
       "|                                                                                                                                                                                     [CSharp, Julia, Python, R, VB]|\n",
       "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(F.array_sort('languagesAtSchool').alias('sorted_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>languagesAtSchool</th><th>languagesAtWork</th><th>currentState</th><th>previousState</th></tr>\n",
       "<tr><td>James Smith</td><td>[Java, Scala, C++, R]</td><td>[Spark, Java]</td><td>OH</td><td>CA</td></tr>\n",
       "<tr><td>Michael Rose</td><td>[Spark, Java, C++, Python, Ruby]</td><td>[Spark, Java]</td><td>NY</td><td>NJ</td></tr>\n",
       "<tr><td>Robert Williams</td><td>[CSharp, VB, Python, R, Julia]</td><td>[Spark, Python]</td><td>UT</td><td>NV</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+--------------------------------+---------------+------------+-------------+\n",
       "|           name|               languagesAtSchool|languagesAtWork|currentState|previousState|\n",
       "+---------------+--------------------------------+---------------+------------+-------------+\n",
       "|    James Smith|           [Java, Scala, C++, R]|  [Spark, Java]|          OH|           CA|\n",
       "|   Michael Rose|[Spark, Java, C++, Python, Ruby]|  [Spark, Java]|          NY|           NJ|\n",
       "|Robert Williams|  [CSharp, VB, Python, R, Julia]|[Spark, Python]|          UT|           NV|\n",
       "+---------------+--------------------------------+---------------+------------+-------------+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    " (\"ABC\", 'Fashion', [\"Spark\",\"Java\"],\"OH\",\"CA\"),\n",
    " (\"MNP\",[\"Spark\",\"Java\",\"C++\", \"Python\", \"Ruby\"],[\"Spark\",\"Java\"],\"NY\",\"NJ\"),\n",
    " (\"XYZ\",[\"CSharp\",\"VB\", \"Python\", \"R\", \"Julia\"],[\"Spark\",\"Python\"],\"UT\",\"NV\")\n",
    "]\n",
    "\n",
    "from pyspark.sql.types import StringType, ArrayType,StructType,StructField\n",
    "schema = StructType([ \n",
    "    StructField(\"isdn\", StringType(), True), \n",
    "    StructField(\"category\", ArrayType(StringType()), True), \n",
    "    StructField(\"products\", ArrayType(StringType()), True), \n",
    "    StructField(\"category_rank\", StringType(), True),\n",
    "  ])\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierrachical array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T18:02:14.625274Z",
     "iopub.status.busy": "2021-07-02T18:02:14.624351Z",
     "iopub.status.idle": "2021-07-02T18:02:21.669364Z",
     "shell.execute_reply": "2021-07-02T18:02:21.668366Z",
     "shell.execute_reply.started": "2021-07-02T18:02:14.625274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>isdn</th><th>demo_recommend</th></tr>\n",
       "<tr><td>0914934576</td><td>[{11, geomancy}, {12, worship_items}, {13, oral_care}, {14, novels}, {15, casual_clothes_men}]</td></tr>\n",
       "<tr><td>0918767457</td><td>[{11, kitchen}, {12, skin_care}, {13, makeup_women}, {14, novels}, {15, home_care}]</td></tr>\n",
       "<tr><td>0364544993</td><td>[{11, headphones}, {12, computers}, {13, snacks}, {14, smartphones}, {15, makeup_men}]</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+----------------------------------------------------------------------------------------------+\n",
       "|      isdn|                                                                                demo_recommend|\n",
       "+----------+----------------------------------------------------------------------------------------------+\n",
       "|0914934576|[{11, geomancy}, {12, worship_items}, {13, oral_care}, {14, novels}, {15, casual_clothes_men}]|\n",
       "|0918767457|           [{11, kitchen}, {12, skin_care}, {13, makeup_women}, {14, novels}, {15, home_care}]|\n",
       "|0364544993|        [{11, headphones}, {12, computers}, {13, snacks}, {14, smartphones}, {15, makeup_men}]|\n",
       "+----------+----------------------------------------------------------------------------------------------+"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    ('0364544993', 'headphones', 11),\n",
    "    ('0364544993', 'computers', 12),\n",
    "    ('0364544993', 'snacks', 13),\n",
    "    ('0364544993', 'smartphones', 14),\n",
    "    ('0364544993', 'makeup_men', 15),\n",
    "    ('0918767457', 'kitchen', 11),\n",
    "    ('0918767457', 'skin_care', 12),\n",
    "    ('0918767457', 'makeup_women', 13),\n",
    "    ('0918767457', 'novels', 14),\n",
    "    ('0918767457', 'home_care', 15),\n",
    "    ('0914934576', 'geomancy', 11),\n",
    "    ('0914934576', 'worship_items', 12),\n",
    "    ('0914934576', 'oral_care', 13),\n",
    "    ('0914934576', 'novels', 14),\n",
    "    ('0914934576', 'casual_clothes_men', 15),\n",
    ")\n",
    "\n",
    "schema = 'isdn string, category string, rank int'\n",
    "\n",
    "df_demo = spark.createDataFrame(data, schema)\n",
    "df_demo = df_demo.groupby('isdn').agg(F.collect_list(F.struct('rank', 'category')).alias('demo_recommend'))\n",
    "df_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:53:46.017123Z",
     "iopub.status.busy": "2021-07-02T17:53:46.017123Z",
     "iopub.status.idle": "2021-07-02T17:53:53.541369Z",
     "shell.execute_reply": "2021-07-02T17:53:53.540029Z",
     "shell.execute_reply.started": "2021-07-02T17:53:46.017123Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>isdn</th><th>beha_recommend</th></tr>\n",
       "<tr><td>0918767457</td><td>[{1, kitchen}, {2, home_care}, {3, food}]</td></tr>\n",
       "<tr><td>0364544993</td><td>[{1, travelling}, {2, sexual_welness}, {3, computer_accessories}, {4, men_shoes}, {5, smartphones}]</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+---------------------------------------------------------------------------------------------------+\n",
       "|      isdn|                                                                                     beha_recommend|\n",
       "+----------+---------------------------------------------------------------------------------------------------+\n",
       "|0918767457|                                                          [{1, kitchen}, {2, home_care}, {3, food}]|\n",
       "|0364544993|[{1, travelling}, {2, sexual_welness}, {3, computer_accessories}, {4, men_shoes}, {5, smartphones}]|\n",
       "+----------+---------------------------------------------------------------------------------------------------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    ('0364544993', 'travelling', 1),\n",
    "    ('0364544993', 'sexual_welness', 2),\n",
    "    ('0364544993', 'computer_accessories', 3),\n",
    "    ('0364544993', 'men_shoes', 4),\n",
    "    ('0364544993', 'smartphones', 5),\n",
    "    ('0918767457', 'kitchen', 1),\n",
    "    ('0918767457', 'home_care', 2),\n",
    "    ('0918767457', 'food', 3),\n",
    ")\n",
    "\n",
    "schema = 'isdn string, category string, rank int'\n",
    "\n",
    "df_beha = spark.createDataFrame(data, schema)\n",
    "df_beha = df_beha.groupby('isdn').agg(F.collect_list(F.struct('rank', 'category')).alias('beha_recommend'))\n",
    "df_beha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T18:06:38.820993Z",
     "iopub.status.busy": "2021-07-02T18:06:38.819995Z",
     "iopub.status.idle": "2021-07-02T18:06:52.451322Z",
     "shell.execute_reply": "2021-07-02T18:06:52.450324Z",
     "shell.execute_reply.started": "2021-07-02T18:06:38.820993Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>isdn</th><th>beha_recommend</th><th>demo_recommend</th></tr>\n",
       "<tr><td>0914934576</td><td>null</td><td>[{11, geomancy}, {12, worship_items}, {13, oral_care}, {14, novels}, {15, casual_clothes_men}]</td></tr>\n",
       "<tr><td>0918767457</td><td>[{1, kitchen}, {2, home_care}, {3, food}]</td><td>[{11, kitchen}, {12, skin_care}, {13, makeup_women}, {14, novels}, {15, home_care}]</td></tr>\n",
       "<tr><td>0364544993</td><td>[{1, travelling}, {2, sexual_welness}, {3, computer_accessories}, {4, men_shoes}, {5, smartphones}]</td><td>[{11, headphones}, {12, computers}, {13, snacks}, {14, smartphones}, {15, makeup_men}]</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+---------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+\n",
       "|      isdn|                                                                                     beha_recommend|                                                                                demo_recommend|\n",
       "+----------+---------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+\n",
       "|0914934576|                                                                                               null|[{11, geomancy}, {12, worship_items}, {13, oral_care}, {14, novels}, {15, casual_clothes_men}]|\n",
       "|0918767457|                                                          [{1, kitchen}, {2, home_care}, {3, food}]|           [{11, kitchen}, {12, skin_care}, {13, makeup_women}, {14, novels}, {15, home_care}]|\n",
       "|0364544993|[{1, travelling}, {2, sexual_welness}, {3, computer_accessories}, {4, men_shoes}, {5, smartphones}]|        [{11, headphones}, {12, computers}, {13, snacks}, {14, smartphones}, {15, makeup_men}]|\n",
       "+----------+---------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_beha.join(df_demo, on='isdn', how='right')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T18:13:17.290162Z",
     "iopub.status.busy": "2021-07-02T18:13:17.289161Z",
     "iopub.status.idle": "2021-07-02T18:13:31.038786Z",
     "shell.execute_reply": "2021-07-02T18:13:31.037790Z",
     "shell.execute_reply.started": "2021-07-02T18:13:17.290162Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>isdn</th><th>pos</th><th>col</th></tr>\n",
       "<tr><td>0918767457</td><td>0</td><td>kitchen</td></tr>\n",
       "<tr><td>0918767457</td><td>1</td><td>home_care</td></tr>\n",
       "<tr><td>0918767457</td><td>2</td><td>food</td></tr>\n",
       "<tr><td>0918767457</td><td>3</td><td>skin_care</td></tr>\n",
       "<tr><td>0918767457</td><td>4</td><td>makeup_women</td></tr>\n",
       "<tr><td>0364544993</td><td>0</td><td>travelling</td></tr>\n",
       "<tr><td>0364544993</td><td>1</td><td>sexual_welness</td></tr>\n",
       "<tr><td>0364544993</td><td>2</td><td>computer_accessories</td></tr>\n",
       "<tr><td>0364544993</td><td>3</td><td>men_shoes</td></tr>\n",
       "<tr><td>0364544993</td><td>4</td><td>smartphones</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+---+--------------------+\n",
       "|      isdn|pos|                 col|\n",
       "+----------+---+--------------------+\n",
       "|0918767457|  0|             kitchen|\n",
       "|0918767457|  1|           home_care|\n",
       "|0918767457|  2|                food|\n",
       "|0918767457|  3|           skin_care|\n",
       "|0918767457|  4|        makeup_women|\n",
       "|0364544993|  0|          travelling|\n",
       "|0364544993|  1|      sexual_welness|\n",
       "|0364544993|  2|computer_accessories|\n",
       "|0364544993|  3|           men_shoes|\n",
       "|0364544993|  4|         smartphones|\n",
       "+----------+---+--------------------+"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\\\n",
    "    .selectExpr('isdn', 'beha_recommend.category AS category_beha', 'demo_recommend.category AS category_demo')\\\n",
    "    .select('isdn', F.concat('category_beha', 'category_demo').alias('recommend'))\\\n",
    "    .select('isdn', F.array_distinct('recommend').alias('recommend'))\\\n",
    "    .selectExpr('isdn', 'SLICE(recommend, 1, 5) AS recommend')\\\n",
    "    .selectExpr('isdn', 'POSEXPLODE(recommend)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*&#9829; By Quang Hung x Thuy Linh &#9829;*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
