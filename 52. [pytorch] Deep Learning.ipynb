{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "[PyTorch] is one of the two most popular Deep Learning frameworks in Python, besides TensorFlow. Here is some key points when comparing the two:\n",
    "- In terms of low or high level, PyTorch falls somewhere in between TensorFlow and Keras. No fit-and-predict interface, must be done by hand.\n",
    "- PyTorch is prefered by research community with more customizations, as we normally see newly published architectures written in PyTorch.\n",
    "- TensorFlow/Keras is better for production due to high-level interface and large deployment ecosystem.\n",
    "\n",
    "[PyTorch]: https://github.com/pytorch/pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-27T15:28:36.207293Z",
     "iopub.status.busy": "2022-12-27T15:28:36.206867Z",
     "iopub.status.idle": "2022-12-27T15:28:40.078882Z",
     "shell.execute_reply": "2022-12-27T15:28:40.078154Z",
     "shell.execute_reply.started": "2022-12-27T15:28:36.207220Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import janitor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "In PyTorch, we work most of the time with\n",
    "<code style='font-size:13px'><a href=https://pytorch.org/docs/stable/tensors.html>Tensor</a></code>\n",
    "whose operations are very much like NumPy's array. Being very natural to PyTorch, tensor operations are provided directly in the [mother package]. One thing to notice is that PyTorch requires tensors to be of the same data type so mathematical computation can be performed on them. When error occurs, simply call the <code style='font-size:13px'>double()</code> method to convert the tensor to float type.\n",
    "\n",
    "[mother package]: https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([\n",
    "    [1., 2., 3.],\n",
    "    [4., 5., 6.]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1039, 0.6032, 0.2776],\n",
       "        [0.3127, 0.8976, 0.3040]], dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand_like(a).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd\n",
    "PyTorch provides automatic differentiation via the module\n",
    "<code style='font-size:13px'><a href=https://pytorch.org/docs/stable/autograd.html>autograd</a></code>,\n",
    "with functions implemented as\n",
    "<code style='font-size:13px'>Tensor</code>\n",
    "methods. Being a mathematical module, it distinguishes two types of tensor, *constant* and *variable*, indicated via the flag <code style='font-size:13px'>requires_grad</code>. All tensors are constants by default, and become variables when this flag is enabled. With variables, we compute the *foward* pass using operations just like normal tensors. The difference is during the *backward* pass (by calling the <code style='font-size:13px'>backward()</code> method on the output variable), PyTorch will compute and accumulate partial derivatives for leaf nodes. This information can be accessed via the <code style='font-size:13px'>grad</code> attribute of input variables.\n",
    "\n",
    "We demonstrate Autograd with a simple Linear Regression problem on the Boston dataset. Note that $\\mathbf{X}$ and $\\mathbf{y}$ are variables of the model, but $\\mathbf{w}$ and $b$ are variables from the perspective of the loss function $\\mathcal{L}$. In this section, $\\mathbf{w}$ and $b$ are randomly initialized and will be optimized later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-27T16:19:52.343913Z",
     "iopub.status.busy": "2022-12-27T16:19:52.343525Z",
     "iopub.status.idle": "2022-12-27T16:19:52.355175Z",
     "shell.execute_reply": "2022-12-27T16:19:52.354115Z",
     "shell.execute_reply.started": "2022-12-27T16:19:52.343887Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([506, 13])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constants\n",
    "df = pd.read_csv('data/boston.csv')\n",
    "x = torch.tensor(df.drop(columns='price').values, dtype=torch.float32)\n",
    "y = torch.tensor(df.price, dtype=torch.float32).reshape(-1, 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-27T16:20:03.904163Z",
     "iopub.status.busy": "2022-12-27T16:20:03.903613Z",
     "iopub.status.idle": "2022-12-27T16:20:03.909202Z",
     "shell.execute_reply": "2022-12-27T16:20:03.907958Z",
     "shell.execute_reply.started": "2022-12-27T16:20:03.904122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# variables\n",
    "w = torch.rand(13, 1, requires_grad=True)\n",
    "b = torch.rand(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-27T16:20:04.977688Z",
     "iopub.status.busy": "2022-12-27T16:20:04.977278Z",
     "iopub.status.idle": "2022-12-27T16:20:04.991206Z",
     "shell.execute_reply": "2022-12-27T16:20:04.990121Z",
     "shell.execute_reply.started": "2022-12-27T16:20:04.977661Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# foward pass\n",
    "yPred = torch.matmul(x, w) + b\n",
    "yTrue = y\n",
    "loss = F.mse_loss(yPred, yTrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-27T16:20:11.693998Z",
     "iopub.status.busy": "2022-12-27T16:20:11.693680Z",
     "iopub.status.idle": "2022-12-27T16:20:11.713341Z",
     "shell.execute_reply": "2022-12-27T16:20:11.712396Z",
     "shell.execute_reply.started": "2022-12-27T16:20:11.693976Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.3905e+03],\n",
       "        [1.1662e+04],\n",
       "        [1.4044e+04],\n",
       "        [7.7154e+01],\n",
       "        [6.5687e+02],\n",
       "        [7.1741e+03],\n",
       "        [8.2400e+04],\n",
       "        [4.1105e+03],\n",
       "        [1.2983e+04],\n",
       "        [5.1313e+05],\n",
       "        [2.1505e+04],\n",
       "        [4.0734e+05],\n",
       "        [1.5525e+04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# backward pass\n",
    "loss.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01, 7.1850e+00,\n",
       "        6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02, 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00], dtype=torch.float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([34.7000], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularData(Dataset):\n",
    "    def __init__(self, df, labelName):\n",
    "        self.features = df.drop(columns=labelName)\n",
    "        self.label = df[labelName]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TabularData at 0x1a72763b550>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TabularData(df, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = w, b\n",
    "optimizer = torch.optim.SGD(params, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nIter = 100\n",
    "for i in range(nIter):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3269, 0.2952, 0.0765],\n",
       "        [0.3269, 0.2952, 0.0765],\n",
       "        [0.3269, 0.2952, 0.0765],\n",
       "        [0.3269, 0.2952, 0.0765],\n",
       "        [0.3269, 0.2952, 0.0765]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch has two APIs for creating layers,\n",
    "<code style='font-size:13px'><a href=https://pytorch.org/docs/stable/nn.html>nn</a></code>\n",
    "(abbreviated for *neural network*) and\n",
    "<code style='font-size:13px'><a href=https://pytorch.org/docs/stable/nn.functional.html>nn.functional</a></code>.\n",
    "The first module provides object interface (that supports auto differentiation) and the second module provides function interface (easier to use). So, the best practice is using object interface for layers with trainable parameters such as recurrent or convolutional, and using function interface for loss functions or activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch has two APIs for creating models, where the recommended one is\n",
    "<code style='font-size:13px'><a href=https://pytorch.org/docs/stable/generated/torch.nn.Module.html>nn.Module</a></code>,\n",
    "being equivalent to functional API in Keras. To create a model, we inherit this class, define building blocks inside the <code style='font-size:13px'>\\_\\_init__()</code> method and design the neural network architecture with the <code style='font-size:13px'>foward()</code> method. We don't need to to specify the backward pass, as the submodule\n",
    "<code style='font-size:13px'><a href=https://pytorch.org/docs/stable/autograd.html>autograd</a></code>\n",
    "will handle it for us. The second API,\n",
    "<code style='font-size:13px'><a href=https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html>nn.Sequential</a></code>,\n",
    "is good for simple architectures as well as small blocks of large networks, inception block of GooLeNet for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.,  8., 10.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.autograd.Variable(torch.Tensor([[1,2,3,4,5]]), requires_grad=True)\n",
    "y = torch.sum(x**2)\n",
    "y.backward() \n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "\n",
    "        D_in: input dimension\n",
    "        H: dimension of hidden layer\n",
    "        D_out: output dimension\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H) \n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must \n",
    "        return a Variable of output data. We can use Modules defined in the \n",
    "        constructor as well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        h_relu = nn.functional.relu(self.linear1(x))\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rectangle:\n",
    "    def __init__(self, length, width):\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "\n",
    "    def area(self):\n",
    "        return self.length * self.width\n",
    "\n",
    "    def perimeter(self):\n",
    "        return 2 * self.length + 2 * self.width\n",
    "\n",
    "class Square(Rectangle):\n",
    "    def __init__(self, length):\n",
    "        super().__init__(length, length)\n",
    "        \n",
    "class Cube(Square):\n",
    "    def surface_area(self):\n",
    "        face_area = super().area()\n",
    "        return face_area * 6\n",
    "\n",
    "    def volume(self):\n",
    "        face_area = super().area()\n",
    "        return face_area * self.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- *pytorch.org - [Autograd mechanics](https://pytorch.org/docs/stable/notes/autograd.html)*\n",
    "- *pytorch.org - [Automatic differentiation with Torch.Autograd](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)*\n",
    "- *pytorch.org - [Deep Learning with PyTorch: A 60-minute blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)*\n",
    "- *towardsdatascience.com - [Understanding PyTorch with an example: a step-by-step tutorial](https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e)*\n",
    "- *towardsdatascience.com - [PyTorch vs TensorFlow - spotting the difference](https://towardsdatascience.com/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b)*\n",
    "- *blog.paperspace.com - [PyTorch 101 advanced](https://blog.paperspace.com/pytorch-101-advanced/)*\n",
    "- *poloclub.github.io - [CNN explainer](https://poloclub.github.io/cnn-explainer/)*\n",
    "- https://cs230.stanford.edu/blog/pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pytorch torchvision torchaudio cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*&#9829; By Quang Hung x Thuy Linh &#9829;*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
