{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Recurrent layers\n",
    "[Recurrent Neural Network] (RNN) is a class of neural network architectures where nodes in a layers have internal connections, allowing to express temporal behaviour. There are many types of RNN layers, but they all share the same architecture. The image below shows the information flow for an observation, or for a document in the context of NLP.\n",
    "\n",
    "<img src='image/rnn_general.png' style='height:200px; margin:20px auto;'>\n",
    "\n",
    "Here, each green cell $\\mathbf{x}_t\\in\\mathbb{R}^{V\\times 1}$ represents the embedding vector of a token, and each blue cell $\\mathbf{h}_t\\in\\mathbb{R}^{D\\times 1}$ represents an output vector. With the input sequence size is fixed at $T$, RNN adjusts itself to match the input length. The most important part of a RNN layer is the grey cell $A$ that repeats multiple times, being account for information processing. We can see that at a time step, the output value $\\mathbf{h}_t$ is influenced by all previous steps $\\mathbf{h}_{t-1},\\mathbf{h}_{t-2},\\dots$, besides the input $\\mathbf{x}_t$. This design resembles *memory* and enables RNN to capture sequential relationship.\n",
    "\n",
    "[Recurrent Neural Network]: https://en.wikipedia.org/wiki/Recurrent_neural_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Simple RNN\n",
    "We call the vanilla architecture [Simple RNN] (1980s) to distinguish from the family name. RNN takes vectorized tokens as input, so that the input will be a tensor size $(N\\times T\\times V)$, where $N$ is the number of observations, $T$ is the sequence length and $V$ is the embedding size.\n",
    "\n",
    "$$\\mathbf{h}_t=\\phi(\\mathbf{W}_x\\mathbf{x}_t+\\mathbf{W}_h\\mathbf{h}_{t-1}+\\mathbf{b}_h)$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{h}_t,\\mathbf{h}_{t-1}\\in\\mathbb{R}$\n",
    "\n",
    "<img src='image/rnn_cell.png' style='height:160px; margin:20px auto;'>\n",
    "\n",
    "<code style='font-size:13px'><a href=https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN>SimpleRNN</a></code>\n",
    "\n",
    "[Simple RNN]: https://en.wikipedia.org/wiki/Recurrent_neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T13:43:01.937803Z",
     "iopub.status.busy": "2022-12-13T13:43:01.937047Z",
     "iopub.status.idle": "2022-12-13T13:43:26.644300Z",
     "shell.execute_reply": "2022-12-13T13:43:26.642848Z",
     "shell.execute_reply.started": "2022-12-13T13:43:01.937681Z"
    }
   },
   "outputs": [],
   "source": [
    "from sspipe import p, px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((32,10,8))\n",
    "y = np.random.random((32,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = layers.SimpleRNN(5)\n",
    "y = rnn(x)\n",
    "# display(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'simple_rnn_48/simple_rnn_cell_49/kernel:0' shape=(8, 5) dtype=float32, numpy=\n",
       " array([[ 0.30787557,  0.279916  ,  0.3244257 , -0.17942247,  0.6445712 ],\n",
       "        [-0.42084822, -0.2789095 , -0.14702582, -0.48875207, -0.32214996],\n",
       "        [-0.1430338 ,  0.6396812 ,  0.06047022,  0.31589776,  0.6563163 ],\n",
       "        [-0.01988047, -0.5084378 , -0.44210398,  0.24137521, -0.29147363],\n",
       "        [ 0.5190995 , -0.5167712 , -0.43493587, -0.2736781 ,  0.6236826 ],\n",
       "        [-0.26117405, -0.09863216, -0.39324647, -0.36624175,  0.22229993],\n",
       "        [-0.59262437, -0.4157125 , -0.3820259 , -0.46295422, -0.5645746 ],\n",
       "        [-0.6424703 ,  0.26339567, -0.3313635 ,  0.385486  ,  0.42365873]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple_rnn_48/simple_rnn_cell_49/recurrent_kernel:0' shape=(5, 5) dtype=float32, numpy=\n",
       " array([[-0.08004582,  0.16700688, -0.3425147 , -0.91969395,  0.05048035],\n",
       "        [-0.6168605 , -0.09782366, -0.7034774 ,  0.30595028,  0.14638162],\n",
       "        [ 0.2573356 ,  0.17859346, -0.3839196 ,  0.10569148, -0.8621588 ],\n",
       "        [-0.72943395,  0.28120798,  0.48281804, -0.08639646, -0.38505906],\n",
       "        [ 0.121574  ,  0.922803  , -0.08541509,  0.20475022,  0.2905784 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple_rnn_48/simple_rnn_cell_49/bias:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_44 (SimpleRNN)   (None, 10, 5)             70        \n",
      "                                                                 \n",
      " simple_rnn_45 (SimpleRNN)   (None, 3)                 27        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                40        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137\n",
      "Trainable params: 137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.SimpleRNN(5, input_shape=(10,8), return_sequences=True),\n",
    "    layers.SimpleRNN(3),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*(1+3+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5*8 + 5*5 + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'simple_rnn_15/simple_rnn_cell_15/kernel:0' shape=(8, 4) dtype=float32, numpy=\n",
       " array([[-0.12565374, -0.17764747,  0.19202441,  0.00790167],\n",
       "        [ 0.42867404,  0.17833441, -0.6105001 ,  0.49296635],\n",
       "        [-0.40300983,  0.3589633 , -0.26932156, -0.41699216],\n",
       "        [-0.28938767,  0.16760606, -0.34825772,  0.5725295 ],\n",
       "        [ 0.3798756 , -0.45982867,  0.30792862, -0.05597204],\n",
       "        [ 0.39521652,  0.21937352,  0.3404147 ,  0.5420316 ],\n",
       "        [ 0.37472934,  0.37950474, -0.04657042,  0.18962324],\n",
       "        [ 0.37935108,  0.24689758, -0.4418146 , -0.25006822]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple_rnn_15/simple_rnn_cell_15/recurrent_kernel:0' shape=(4, 4) dtype=float32, numpy=\n",
       " array([[-0.80420995, -0.04441664,  0.47590402,  0.35325453],\n",
       "        [ 0.07364351, -0.4747402 ,  0.57299924, -0.6639806 ],\n",
       "        [-0.29404065,  0.7626039 ,  0.0019677 , -0.57616967],\n",
       "        [-0.51123667, -0.4371317 , -0.66722065, -0.31995237]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple_rnn_15/simple_rnn_cell_15/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(4, 4)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "_ = [print(weight.shape) for weight in model.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.6159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f277c7ee0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. LSTM\n",
    "[LSTM] (Long Short-Term Memory, 1997)\n",
    "\n",
    "<img src='image/lstm_cell.png' style='height:320px; margin:20px auto;'>\n",
    "\n",
    "<code style='font-size:13px'><a href=https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM>LSTM</a></code>\n",
    "\n",
    "[LSTM]: https://en.wikipedia.org/wiki/Long_short-term_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='image/lstm_steps.png' style='height:520px; margin:20px auto;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. GRU\n",
    "[Gated Recurrent Units] (GRU)\n",
    "\n",
    "<img src='image/gru_cell.png' style='height:320px; margin:20px auto;'>\n",
    "\n",
    "<code style='font-size:13px'><a href=https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU>GRU</a></code>\n",
    "\n",
    "[Gated Recurrent Units]: https://en.wikipedia.org/wiki/Gated_recurrent_unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Bi-directional\n",
    "\n",
    "<img src='image/rnn_bidirectional.png' style='height:280px; margin:20px auto;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Recurrent architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Seq2seq\n",
    "[Seq2seq]\n",
    "\n",
    "[Seq2seq]: https://en.wikipedia.org/wiki/Seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Attention\n",
    "[Attention] implement\n",
    "<code style='font-size:13px'><a href=https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention>Attention</a></code>\n",
    "\n",
    "[Attention]: https://en.wikipedia.org/wiki/Attention_(machine_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Transformer\n",
    "[Transformer]\n",
    "\n",
    "[Transformer]: https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- *amitness.com - [Recurrent Keras layer](https://amitness.com/2020/04/recurrent-layers-keras/)*\n",
    "- *colah.github.io - [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)*\n",
    "- *distill.pub - [Memorization in RNNs](https://distill.pub/2019/memorization-in-rnns/)*\n",
    "- *distill.pub - [Augumented RNNs](https://distill.pub/2016/augmented-rnns/)*\n",
    "---\n",
    "- https://www.kaggle.com/code/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert\n",
    "- https://www.kaggle.com/code/kredy10/simple-lstm-for-text-classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
