{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1. Thuật toán\n",
    "\n",
    "Thuật toán hồi quy logistic [Logistic Regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression) chỉ khác linear regression đó là biến đầu ra $\\mathbf{y}$ thay vì là giá trị liên tục thì chỉ nhận 1 trong 2 giá trị 0 (negative) hoặc 1 (positive). Vì vậy hồi quy logistic được sử dụng trong bài toán phân lớp. Chính xác hơn, đầu ra của thuật toán là giá trị nằm trong khoảng $[0,1]$ - là xác suất rơi vào nhóm positive của các quan sát. Hàm hồi quy sẽ có dạng:\n",
    "\n",
    "$$\\mathbf{p} = \\frac{1}{1+e^{-(w_0+w_1\\mathbf{x}_1+w_2\\mathbf{x}_2+\\dots)}}$$\n",
    "\n",
    "Trong đó:\n",
    "- $\\mathbf{y}=y_1,y_2,\\dots,y_N$ là biến đầu ra\n",
    "- $\\mathbf{p}=p_1,p_2,\\dots,p_N$, $p_n=P(y_n=1|\\mathbf{x}_n;\\mathbf{w})$ là xác suất để $y_n=1$\n",
    "- $\\mathbf{x}_1,\\mathbf{x}_2,\\dots$ là các biến đầu vào\n",
    "- $w_0,w_1,w_2,\\dots$ là hệ số của hàm hồi quy\n",
    "\n",
    "Một cách viết khác của hàm hồi quy là tỷ số odds (tỷ lệ success so với failed) cũng hay được sử dụng. Đây chính là dạng tuyến tính của mô hình hồi quy logistic:\n",
    "\n",
    "$$\\ln(\\frac{\\mathbf{p}}{1-\\mathbf{p}}) = w_0+w_1\\mathbf{x}_1+w_2\\mathbf{x}_2+\\dots$$\n",
    "\n",
    "Công thức tổng quát của hàm hồi quy có dạng: $\\mathbf{p}=f(\\mathbf{X}\\mathbf{w})$, với $f$ là hàm logistic tiêu chuẩn, đạo hàm của $f$ sẽ tuân theo phân phối logistic, $f$ thường là hàm sigmoid:\n",
    "\n",
    "$$f(x)=\\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood vs Probability "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hàm mất mát\n",
    "\n",
    "Đạo hàm hàm hồi quy ta có $P(\\mathbf{y}=1)=f(\\mathbf{X}\\mathbf{w})$ và $P(\\mathbf{y}=0)=1-f(\\mathbf{X}\\mathbf{w})$.\n",
    "Công thức tổng quát sẽ cho ta giá trị likelihood:\n",
    "\n",
    "$$P(\\mathbf{y}=y|\\mathbf{X}) = p^y(1-p)^{1-y} = \\prod{p_i^{y_i}(1-p_i)^{1-y_i}}$$\n",
    "\n",
    "Mục tiêu là tối đa hóa giá trị likelihood $P$ - khi $P$ càng lớn các điểm sẽ càng được phân lớp rõ ràng, tuy nhiên để tối ưu hàm số trên theo $w$ sẽ rất khó khăn, vì vậy ta lấy log 2 vế và thay vì tìm cực đại likelihood, ta sẽ tìm cực tiểu của log-likelihood. Đây là phương pháp [MLE](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation). Hàm mất mát sẽ có dạng:\n",
    "\n",
    "$$L(\\mathbf{w}) = -\\log P(\\mathbf{y}|\\mathbf{X}) = \\sum{\\left[y_i\\log{p_i}+(1-y_i)\\log{(1-p_i)}\\right]}$$\n",
    "\n",
    "Vector hệ số $\\mathbf{w}$ thỏa mãn: $\\hat{\\mathbf{w}} =\\arg\\min L(\\mathbf{w})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Implementation\n",
    "[Logistic Regression implementation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) không có siêu tham số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>bad_customer</th>\n",
       "      <th>credit_balance_percent</th>\n",
       "      <th>age</th>\n",
       "      <th>num_of_group1_pastdue</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>income</th>\n",
       "      <th>num_of_loans</th>\n",
       "      <th>num_of_times_late_90days</th>\n",
       "      <th>num_of_estate_loans</th>\n",
       "      <th>num_of_group2_pastdue</th>\n",
       "      <th>num_of_dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  bad_customer  credit_balance_percent  age  num_of_group1_pastdue  \\\n",
       "0      0             1                0.766127   45                      2   \n",
       "1      1             0                0.957151   40                      0   \n",
       "2      2             0                0.658180   38                      1   \n",
       "3      3             0                0.233810   30                      0   \n",
       "4      4             0                0.907239   49                      1   \n",
       "\n",
       "   debt_ratio   income  num_of_loans  num_of_times_late_90days  \\\n",
       "0    0.802982   9120.0            13                         0   \n",
       "1    0.121876   2600.0             4                         0   \n",
       "2    0.085113   3042.0             2                         1   \n",
       "3    0.036050   3300.0             5                         0   \n",
       "4    0.024926  63588.0             7                         0   \n",
       "\n",
       "   num_of_estate_loans  num_of_group2_pastdue  num_of_dependents  \n",
       "0                    6                      0                2.0  \n",
       "1                    0                      0                1.0  \n",
       "2                    0                      0                0.0  \n",
       "3                    0                      0                0.0  \n",
       "4                    1                      0                0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit = pd.read_csv('data/credit_scoring.csv')\n",
    "credit = credit.dropna().reset_index()\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = credit.bad_customer.values\n",
    "X = credit.drop(columns='bad_customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = logistic.predict(X_train)\n",
    "y_test_pred = logistic.predict(X_test)\n",
    "y_test_prob_pred = logistic.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>class_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.980067</td>\n",
       "      <td>0.019933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.942151</td>\n",
       "      <td>0.057849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973669</td>\n",
       "      <td>0.026331</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.938395</td>\n",
       "      <td>0.061605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.923867</td>\n",
       "      <td>0.076133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1  class_\n",
       "0  0.980067  0.019933       0\n",
       "1  0.942151  0.057849       0\n",
       "2  0.973669  0.026331       0\n",
       "3  0.938395  0.061605       0\n",
       "4  0.923867  0.076133       0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = pd.DataFrame(y_test_prob_pred)\n",
    "prob = prob.assign(class_=y_test_pred)\n",
    "prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     89539\n",
      "           1       0.58      0.04      0.08      6676\n",
      "\n",
      "    accuracy                           0.93     96215\n",
      "   macro avg       0.76      0.52      0.52     96215\n",
      "weighted avg       0.91      0.93      0.90     96215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     22373\n",
      "           1       0.53      0.04      0.08      1681\n",
      "\n",
      "    accuracy                           0.93     24054\n",
      "   macro avg       0.73      0.52      0.52     24054\n",
      "weighted avg       0.90      0.93      0.90     24054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1. Định lý Bayes\n",
    "\n",
    "Định lý bayes được sử dụng để tìm xác suất có điều kiện của event A khi chúng ta biết các sự kiện có liên quan. Giả sử \n",
    "$P(A)>0$ và ${B_1, B_2,\\dots,B_n}$ là một tập hợp các sự kiện hoàn chỉnh. Với $k=1,2,\\dots,n$ ta có:\n",
    "\n",
    "$$P(B_k|A) = \\frac{P(A|B_k)\\cdot P(B_k)}{P(B_1)P(A|B_1)+P(B_2)\\cdot P(A|B_2)+\\dots+P(B_n)\\cdot P(A|B_n)}$$\n",
    "\n",
    "- $P(B_k|A)$ là xác suất có điều kiện: Xác suất của sự kiện $B_k$ xảy ra với điều kiện $A$ đã xảy ra. Đây còn được gọi là posterior probability của $B_k$ với $A$ cho trước.\n",
    "- $P(A|B_k)$ cũng là xác suất có điều kiện: Xác suất của sự kiện $A$ xảy ra với điều kiện $B_k$ xảy ra \n",
    "- $P(A)$ và $P(B_k)$  là xác suất của các quan sát $A$ và $B_k$ khi độc lập hoàn toàn, còn được gọi là marginal probability hay prior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Thuật toán\n",
    "[Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html) là thuật toán dựa trên định lý bayes [Bayes' theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem). Với bài toán phân loại, ta có tập hợp các biến đầu vào là $\\mathbf{X}=\\mathbf{x}_1,\\mathbf{x}_2,\\dots$ và $\\mathbf{y}$ là biến đầu ra, định lý bayes được viết tổng quát là: \n",
    "\n",
    "$$P(\\mathbf{y}|\\mathbf{X}) = \\frac{P(\\mathbf{X}|\\mathbf{y})P(\\mathbf{y})}{P(\\mathbf{X})}$$\n",
    "\n",
    "- $P(\\mathbf{y}|\\mathbf{X})$ is the posterior probability, the probability of a class for given predictors\n",
    "- $P(\\mathbf{X}|\\mathbf{y})$ is the likelihood, the probability of predictors for a given class\n",
    "- $P(\\mathbf{y})$ is the prior probability of a class\n",
    "- $P(\\mathbf{X})$ is the prior probability of predictors\n",
    "\n",
    "Công thức dưới đây mô tả cách thuật toán phân loại các quan sát vào các lớp $c$:\n",
    "\n",
    "$$\\hat{\\mathbf{y}} = \\arg\\max P(\\mathbf{y}=c|\\mathbf{X}) =\n",
    "\\arg\\max P(\\mathbf{X}|\\mathbf{y}=c)P(\\mathbf{y}=c)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ước lượng giá trị likelihood\n",
    "Naive Bayes assumes that $\\mathbf{x}_1,\\mathbf{x}_2,\\dots$ are independent of each other. This assumption looks quite unrealistic, explains why the algorithm is considered naive. However, Naive Bayes performs surprisingly well in real-world classification problems. The likelihood can be written under this assumption:\n",
    "\n",
    "$$P(\\mathbf{x}_1,\\mathbf{x}_2,\\dots|\\mathbf{y}) = \\prod{P(\\mathbf{x}_i|\\mathbf{y})}$$\n",
    "\n",
    "To estimate $P(\\mathbf{x}_i|\\mathbf{y})$, there are three distributions can be used, depending on the input data:\n",
    "- Gaussian distribution, used when the input data is continuous. The parameters $\\mu_{\\mathbf{y}}$ and $\\sigma_{\\mathbf{y}}$ are estimated using maximum likelihood.\n",
    "\n",
    "$$P(\\mathbf{x}_i|\\mathbf{y}) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_{\\mathbf{y}}}} \\exp\\left(-\\frac{(\\mathbf{x}_i - \\mu_{\\mathbf{y}})^2}{2\\sigma^2_{\\mathbf{y}}}\\right)$$\n",
    "\n",
    "- Multinomial distribution, used when the input data is categorical data. Widely used in text classification. In this formula, $N$ represents the number of observations, $\\alpha$ represents the Laplace smooth coefficient, $d$ is the number of words. $\\alpha=1$ is usually chosen, prevents the probability to be 0.\n",
    "\n",
    "$$P(\\mathbf{x}_i|\\mathbf{y}) = \\frac{N(\\mathbf{x}_i|\\mathbf{y})+\\alpha}{N(\\mathbf{y})+\\alpha d}$$\n",
    "\n",
    "- Bernoulli distribution, used for binary input data.\n",
    "\n",
    "$$P(\\mathbf{x}_i|\\mathbf{y}) = p_i^{\\mathbf{x}_i}(1-p_i)^{1-\\mathbf{x}_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular data\n",
    "This section uses the Iris data, where input variables are continuous. For a mixed types dataset, we use `GaussianNB` for continuous input and `MultinomialNB` for categorical input, then multiply the predicted probability of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = GaussianNB()\n",
    "bayes = bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = bayes.predict(X_train)\n",
    "y_test_pred = bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       0.94      0.91      0.92        32\n",
      "           2       0.92      0.95      0.93        37\n",
      "\n",
      "    accuracy                           0.95       105\n",
      "   macro avg       0.95      0.95      0.95       105\n",
      "weighted avg       0.95      0.95      0.95       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.94      0.89      0.91        18\n",
      "           2       0.86      0.92      0.89        13\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text data\n",
    "Text data is preprocessed so that each column represents a word, each row represents a graph. This table shows how many times a word occurs in a graph. Then apply `MultinomialNB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([\n",
    "    [2, 2, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 3, 0, 1, 2, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 2, 1, 1]\n",
    "])\n",
    "y_train = np.array(['A', 'A', 'A', 'B'])\n",
    "\n",
    "X_test = np.array([\n",
    "    [1, 2, 0, 1, 0, 0, 0, 1, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 0, 1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = MultinomialNB()\n",
    "bayes = bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B'], dtype='<U1')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93708063, 0.06291937],\n",
       "       [0.34255957, 0.65744043]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.predict_proba(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
